{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwWPSYKD0GoQ",
        "outputId": "4ef9ec5f-95d4-447d-fcbc-c82d3bd73167"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cs484'...\n",
            "remote: Enumerating objects: 301, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 301 (delta 8), reused 16 (delta 5), pack-reused 282\u001b[K\n",
            "Receiving objects: 100% (301/301), 83.51 MiB | 17.68 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf cs484 && git clone https://github.com/berkan-sahin/cs484.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -U torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Nvh0OLr9c2j",
        "outputId": "ded90473-c418-493d-9970-2acfc9e680e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
        "import time\n",
        "import copy\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZmY-amFpSQm8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HockeyDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, transformer) -> None:\n",
        "        self.data_dir = data_dir\n",
        "        self.transformer = transformer\n",
        "\n",
        "    def __len__(self):\n",
        "        return 192\n",
        "\n",
        "    def __getitem__(self, index) -> Tuple[any, any]:\n",
        "        class_idx = index / 64\n",
        "        if (class_idx < 1):\n",
        "            class_name = 'freehit'\n",
        "        elif (class_idx < 2):\n",
        "            class_name = 'goal'\n",
        "        elif (class_idx < 3):\n",
        "            class_name = 'penaltycorner'\n",
        "        else:\n",
        "            class_name = 'penaltyshot'  # should never happen\n",
        "\n",
        "        img_name = os.path.join(self.data_dir, class_name,\n",
        "                                f'{(index % 64) + 1}.jpg')\n",
        "        image = read_image(img_name).to(torch.float32)\n",
        "        image = self.transformer(image)\n",
        "        return image, class_idx\n",
        "\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    transforms.Resize(256, antialias=True),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    # transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "rmyKvWKX7ive"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- modified the learning rate (from 0.0001 to 0.001)\n",
        "- using pytorch's pretrained weights\n",
        "- freezing the feature detection layers\n",
        "- bugfixes\n",
        "- batch size incremented to 32 from 4"
      ],
      "metadata": {
        "id": "LJ1LgTGXRGmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if True:    \n",
        "    fold = 6\n",
        "    epochs = 50\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device: \", device)\n",
        "    #vgg16 = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
        "    vgg16 = models.vgg16_bn(weights=models.VGG16_BN_Weights.IMAGENET1K_V1)\n",
        "    # vgg16.load_state_dict(torch.load('vgg16.pth'))\n",
        "    # reset the last layer\n",
        "    # Freeze training for all layers\n",
        "    for param in vgg16.features.parameters():\n",
        "      param.require_grad = False\n",
        "\n",
        "    in_features = vgg16.classifier[-1].in_features\n",
        "    classifier = list(vgg16.classifier.children())[:-1]\n",
        "    classifier.extend([nn.Linear(in_features, 3)])\n",
        "    vgg16.classifier = nn.Sequential(*classifier)\n",
        "    print(vgg16.classifier)\n",
        "    vgg16 = vgg16.to(device)\n",
        "    if torch.cuda.is_available():\n",
        "        vgg16.cuda()\n",
        "    dataset = HockeyDataset(\n",
        "        'cs484/dataset', models.VGG16_Weights.IMAGENET1K_V1.transforms(antialias=True))\n",
        "    # kfold = KFold(n_splits=fold, shuffle=True)\n",
        "    kfold = StratifiedKFold(n_splits=fold, shuffle=True, random_state=3)\n",
        "\n",
        " #   train_size = int(0.8 * len(dataset))\n",
        " #   test_size = len(dataset) - train_size\n",
        " #   train, test = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "    begin = time.time()\n",
        "    initial_weight = copy.deepcopy(vgg16.state_dict())\n",
        "    accuracy = []\n",
        "    best_epochs = []\n",
        "    for (fold, (train, test)) in enumerate(kfold.split(dataset, np.full(64, 0).tolist() + np.full(64, 1).tolist() + np.full(64, 2).tolist())):\n",
        "        print(\"Train: \", train, \"Validation: \", test)\n",
        "        trainloader = DataLoader(dataset, batch_size=40, sampler=train, num_workers=2)\n",
        "        valloader = DataLoader(dataset, batch_size=40, sampler=test, num_workers=2)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(vgg16.parameters(), lr=0.002)\n",
        "        #optimizer_ft = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
        "        scheduler = optim.lr_scheduler.StepLR(\n",
        "               optimizer, step_size=25, gamma=0.85)\n",
        "\n",
        "        vgg16.load_state_dict(initial_weight)\n",
        "        best_weight = copy.deepcopy(initial_weight)\n",
        "        best_acc = 0.0\n",
        "        best_epoch = 0\n",
        "        for epoch in range(epochs):\n",
        "            # Training phase\n",
        "            vgg16.train()\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            for inputs, labels in trainloader:\n",
        "                labels = labels.type(torch.LongTensor)\n",
        "                #inputs = inputs.to(device)\n",
        "                #labels = labels.to(device)\n",
        "\n",
        "                if torch.cuda.is_available():\n",
        "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
        "                else:\n",
        "                    inputs, labels = Variable(inputs), Variable(labels)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = vgg16(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                #print(type(labels))\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                scheduler.step()\n",
        "\n",
        "                del inputs, outputs, labels, preds\n",
        "\n",
        "            epoch_loss = running_loss / len(train)\n",
        "            epoch_acc = running_corrects.double() / len(train)\n",
        "            print('Epoch: {} train Loss: {:.4f} Acc: {:.4f}'.format(epoch, epoch_loss, epoch_acc))\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            vgg16.eval()\n",
        "            with torch.no_grad():\n",
        "                for images, labels in valloader:\n",
        "                    labels = labels.type(torch.LongTensor)\n",
        "                    optimizer.zero_grad()\n",
        "                    #images = images.to(device)\n",
        "                    #labels = labels.to(device)\n",
        "\n",
        "                    if torch.cuda.is_available():\n",
        "                      images, labels = Variable(images.cuda()), Variable(labels.cuda())\n",
        "                    else:\n",
        "                      images, labels = Variable(images), Variable(labels)\n",
        "                    outputs = vgg16(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    running_loss += loss.item() * images.size(0)\n",
        "                    running_corrects += torch.sum(predicted == labels.data)\n",
        "            \n",
        "            epoch_loss = running_loss / len(test)\n",
        "            epoch_acc = running_corrects.double() / len(test)\n",
        "            print('Epoch: {} eval Loss: {:.4f} Acc: {:.4f}'.format(epoch, epoch_loss, epoch_acc))\n",
        "\n",
        "            if epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_weight = copy.deepcopy(vgg16.state_dict())\n",
        "                best_epoch = epoch\n",
        "        \n",
        "        accuracy.append(best_acc)\n",
        "        best_epochs.append(best_epoch)\n",
        "        print(f\"Fold {fold} accuracy: {best_acc} achieved in epoch {best_epoch}\")\n",
        "        #torch.save(best_weight, f\"vgg16_fold{fold}.pth\")\n",
        "\n",
        "\n",
        "    time_elapsed = time.time() - begin\n",
        "    print(f\"Finished Training, took {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
        "    print(f\"Average accuracy: {sum(accuracy) / len(accuracy)}\")\n",
        "    print(f\"Average epoch: {sum(best_epochs) / len(best_epochs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQz9chVi7p6O",
        "outputId": "148bf117-1a46-482e-acb9-6e1c4349e246"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device:  cuda:0\n",
            "Sequential(\n",
            "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): Dropout(p=0.5, inplace=False)\n",
            "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): Dropout(p=0.5, inplace=False)\n",
            "  (6): Linear(in_features=4096, out_features=3, bias=True)\n",
            ")\n",
            "Train:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  15  17  18  19  20\n",
            "  21  22  23  24  25  26  27  29  30  31  32  33  35  37  39  40  41  42\n",
            "  43  44  45  46  47  48  49  50  51  52  53  55  56  59  61  62  63  64\n",
            "  65  67  69  71  72  74  75  76  77  78  79  80  81  84  86  87  88  89\n",
            "  90  92  93  94  95  96  97  98  99 101 102 103 104 105 107 108 109 110\n",
            " 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 131\n",
            " 132 133 135 136 137 138 139 140 141 143 144 145 146 147 148 149 150 152\n",
            " 153 154 155 156 157 159 160 161 162 163 164 165 166 167 169 170 171 172\n",
            " 173 174 175 176 178 180 181 182 183 184 185 186 188 189 190 191] Validation:  [  0  14  16  28  34  36  38  54  57  58  60  66  68  70  73  82  83  85\n",
            "  91 100 106 111 129 130 134 142 151 158 168 177 179 187]\n",
            "Epoch: 0 train Loss: 44.9665 Acc: 0.3500\n",
            "Epoch: 0 eval Loss: 1.1268 Acc: 0.3438\n",
            "Epoch: 1 train Loss: 1.3286 Acc: 0.2250\n",
            "Epoch: 1 eval Loss: 1.1802 Acc: 0.3125\n",
            "Epoch: 2 train Loss: 1.0951 Acc: 0.3500\n",
            "Epoch: 2 eval Loss: 5.1647 Acc: 0.3125\n",
            "Epoch: 3 train Loss: 1.0528 Acc: 0.3375\n",
            "Epoch: 3 eval Loss: 4.7562 Acc: 0.3125\n",
            "Epoch: 4 train Loss: 0.9372 Acc: 0.4188\n",
            "Epoch: 4 eval Loss: 2.3963 Acc: 0.3125\n",
            "Epoch: 5 train Loss: 0.8797 Acc: 0.5625\n",
            "Epoch: 5 eval Loss: 2.0456 Acc: 0.3125\n",
            "Epoch: 6 train Loss: 0.7389 Acc: 0.6375\n",
            "Epoch: 6 eval Loss: 1.9740 Acc: 0.3125\n",
            "Epoch: 7 train Loss: 0.7146 Acc: 0.6313\n",
            "Epoch: 7 eval Loss: 1.5524 Acc: 0.3438\n",
            "Epoch: 8 train Loss: 0.6490 Acc: 0.6875\n",
            "Epoch: 8 eval Loss: 1.4135 Acc: 0.3750\n",
            "Epoch: 9 train Loss: 1.0823 Acc: 0.3875\n",
            "Epoch: 9 eval Loss: 1.9940 Acc: 0.3438\n",
            "Epoch: 10 train Loss: 0.9022 Acc: 0.5438\n",
            "Epoch: 10 eval Loss: 2.2856 Acc: 0.4688\n",
            "Epoch: 11 train Loss: 0.8512 Acc: 0.5312\n",
            "Epoch: 11 eval Loss: 2.1323 Acc: 0.4375\n",
            "Epoch: 12 train Loss: 0.7197 Acc: 0.5750\n",
            "Epoch: 12 eval Loss: 1.8360 Acc: 0.4375\n",
            "Epoch: 13 train Loss: 0.6097 Acc: 0.6938\n",
            "Epoch: 13 eval Loss: 1.5991 Acc: 0.4062\n",
            "Epoch: 14 train Loss: 0.5747 Acc: 0.7688\n",
            "Epoch: 14 eval Loss: 1.3355 Acc: 0.3750\n",
            "Epoch: 15 train Loss: 0.7261 Acc: 0.6188\n",
            "Epoch: 15 eval Loss: 1.5872 Acc: 0.4375\n",
            "Epoch: 16 train Loss: 0.5766 Acc: 0.7563\n",
            "Epoch: 16 eval Loss: 3.2651 Acc: 0.4062\n",
            "Epoch: 17 train Loss: 0.8072 Acc: 0.7438\n",
            "Epoch: 17 eval Loss: 1.9811 Acc: 0.4062\n",
            "Epoch: 18 train Loss: 0.4581 Acc: 0.7688\n",
            "Epoch: 18 eval Loss: 1.0498 Acc: 0.4062\n",
            "Epoch: 19 train Loss: 0.3670 Acc: 0.8000\n",
            "Epoch: 19 eval Loss: 1.0722 Acc: 0.3125\n",
            "Epoch: 20 train Loss: 0.3824 Acc: 0.8063\n",
            "Epoch: 20 eval Loss: 1.1649 Acc: 0.3125\n",
            "Epoch: 21 train Loss: 0.3143 Acc: 0.8375\n",
            "Epoch: 21 eval Loss: 1.3678 Acc: 0.3438\n",
            "Epoch: 22 train Loss: 0.2522 Acc: 0.8875\n",
            "Epoch: 22 eval Loss: 1.6948 Acc: 0.3125\n",
            "Epoch: 23 train Loss: 0.2252 Acc: 0.9250\n",
            "Epoch: 23 eval Loss: 1.8534 Acc: 0.3125\n",
            "Epoch: 24 train Loss: 0.2178 Acc: 0.9500\n",
            "Epoch: 24 eval Loss: 1.5373 Acc: 0.3438\n",
            "Epoch: 25 train Loss: 0.2011 Acc: 0.9625\n",
            "Epoch: 25 eval Loss: 1.5636 Acc: 0.3438\n",
            "Epoch: 26 train Loss: 0.1330 Acc: 0.9875\n",
            "Epoch: 26 eval Loss: 1.7692 Acc: 0.3438\n",
            "Epoch: 27 train Loss: 0.1230 Acc: 0.9750\n",
            "Epoch: 27 eval Loss: 1.8756 Acc: 0.3438\n",
            "Epoch: 28 train Loss: 0.1011 Acc: 0.9875\n",
            "Epoch: 28 eval Loss: 1.7892 Acc: 0.4062\n",
            "Epoch: 29 train Loss: 0.0954 Acc: 0.9875\n",
            "Epoch: 29 eval Loss: 1.9008 Acc: 0.3750\n",
            "Epoch: 30 train Loss: 0.0748 Acc: 0.9875\n",
            "Epoch: 30 eval Loss: 2.0916 Acc: 0.3750\n",
            "Epoch: 31 train Loss: 0.0663 Acc: 0.9875\n",
            "Epoch: 31 eval Loss: 2.2720 Acc: 0.3438\n",
            "Epoch: 32 train Loss: 0.0591 Acc: 0.9875\n",
            "Epoch: 32 eval Loss: 2.4513 Acc: 0.3438\n",
            "Epoch: 33 train Loss: 0.0745 Acc: 0.9750\n",
            "Epoch: 33 eval Loss: 2.7116 Acc: 0.3438\n",
            "Epoch: 34 train Loss: 0.0566 Acc: 0.9875\n",
            "Epoch: 34 eval Loss: 2.8956 Acc: 0.3438\n",
            "Epoch: 35 train Loss: 0.0503 Acc: 0.9875\n",
            "Epoch: 35 eval Loss: 3.0324 Acc: 0.3750\n",
            "Epoch: 36 train Loss: 0.0499 Acc: 0.9875\n",
            "Epoch: 36 eval Loss: 3.1168 Acc: 0.3750\n",
            "Epoch: 37 train Loss: 0.0542 Acc: 0.9875\n",
            "Epoch: 37 eval Loss: 3.2365 Acc: 0.3750\n",
            "Epoch: 38 train Loss: 0.0527 Acc: 0.9875\n",
            "Epoch: 38 eval Loss: 3.2625 Acc: 0.3750\n",
            "Epoch: 39 train Loss: 0.0555 Acc: 0.9875\n",
            "Epoch: 39 eval Loss: 3.2644 Acc: 0.3750\n",
            "Epoch: 40 train Loss: 0.0630 Acc: 0.9875\n",
            "Epoch: 40 eval Loss: 3.2694 Acc: 0.3750\n",
            "Epoch: 41 train Loss: 0.0538 Acc: 0.9875\n",
            "Epoch: 41 eval Loss: 3.2898 Acc: 0.3750\n",
            "Epoch: 42 train Loss: 0.0495 Acc: 0.9875\n",
            "Epoch: 42 eval Loss: 3.3452 Acc: 0.3750\n",
            "Epoch: 43 train Loss: 0.0528 Acc: 0.9875\n",
            "Epoch: 43 eval Loss: 3.4031 Acc: 0.3750\n",
            "Epoch: 44 train Loss: 0.0494 Acc: 0.9875\n",
            "Epoch: 44 eval Loss: 3.4616 Acc: 0.3438\n",
            "Epoch: 45 train Loss: 0.0507 Acc: 0.9875\n",
            "Epoch: 45 eval Loss: 3.5136 Acc: 0.3438\n",
            "Epoch: 46 train Loss: 0.0547 Acc: 0.9875\n",
            "Epoch: 46 eval Loss: 3.5581 Acc: 0.3438\n",
            "Epoch: 47 train Loss: 0.0427 Acc: 0.9875\n",
            "Epoch: 47 eval Loss: 3.6031 Acc: 0.3438\n",
            "Epoch: 48 train Loss: 0.0425 Acc: 0.9875\n",
            "Epoch: 48 eval Loss: 3.6600 Acc: 0.3438\n",
            "Epoch: 49 train Loss: 0.0451 Acc: 0.9875\n",
            "Epoch: 49 eval Loss: 3.7269 Acc: 0.3438\n",
            "Fold 0 accuracy: 0.46875 achieved in epoch 10\n",
            "Train:  [  0   1   2   3   4   5   6   7   8  10  12  13  14  15  16  18  19  20\n",
            "  21  22  25  27  28  29  30  31  32  33  34  35  36  37  38  39  40  42\n",
            "  44  45  46  48  49  50  51  52  53  54  57  58  59  60  61  62  63  64\n",
            "  66  67  68  69  70  71  73  74  75  76  77  79  80  81  82  83  84  85\n",
            "  86  87  89  90  91  93  94  95  97  98  99 100 101 102 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 117 118 121 122 123 124 126 127 128 129\n",
            " 130 131 132 134 135 136 137 138 139 140 142 143 144 145 146 149 150 151\n",
            " 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 170\n",
            " 171 173 174 175 176 177 178 179 180 184 185 186 187 188 189 190] Validation:  [  9  11  17  23  24  26  41  43  47  55  56  65  72  78  88  92  96 103\n",
            " 116 119 120 125 133 141 147 148 169 172 181 182 183 191]\n",
            "Epoch: 0 train Loss: 45.7553 Acc: 0.2500\n",
            "Epoch: 0 eval Loss: 3.0091 Acc: 0.3438\n",
            "Epoch: 1 train Loss: 1.2656 Acc: 0.3375\n",
            "Epoch: 1 eval Loss: 1.2108 Acc: 0.3125\n",
            "Epoch: 2 train Loss: 1.0781 Acc: 0.4125\n",
            "Epoch: 2 eval Loss: 330.9255 Acc: 0.3125\n",
            "Epoch: 3 train Loss: 1.0748 Acc: 0.4313\n",
            "Epoch: 3 eval Loss: 153.9104 Acc: 0.3125\n",
            "Epoch: 4 train Loss: 1.0477 Acc: 0.5125\n",
            "Epoch: 4 eval Loss: 48.1585 Acc: 0.3125\n",
            "Epoch: 5 train Loss: 1.0400 Acc: 0.5625\n",
            "Epoch: 5 eval Loss: 12.1044 Acc: 0.4062\n",
            "Epoch: 6 train Loss: 0.9648 Acc: 0.5813\n",
            "Epoch: 6 eval Loss: 4.0202 Acc: 0.3750\n",
            "Epoch: 7 train Loss: 0.9173 Acc: 0.6500\n",
            "Epoch: 7 eval Loss: 2.2312 Acc: 0.4375\n",
            "Epoch: 8 train Loss: 0.8650 Acc: 0.6313\n",
            "Epoch: 8 eval Loss: 1.4596 Acc: 0.4688\n",
            "Epoch: 9 train Loss: 0.8313 Acc: 0.6688\n",
            "Epoch: 9 eval Loss: 1.2708 Acc: 0.5000\n",
            "Epoch: 10 train Loss: 0.7465 Acc: 0.6750\n",
            "Epoch: 10 eval Loss: 1.1365 Acc: 0.3750\n",
            "Epoch: 11 train Loss: 0.6910 Acc: 0.7313\n",
            "Epoch: 11 eval Loss: 0.9876 Acc: 0.5938\n",
            "Epoch: 12 train Loss: 0.6533 Acc: 0.7375\n",
            "Epoch: 12 eval Loss: 0.8921 Acc: 0.5625\n",
            "Epoch: 13 train Loss: 0.5999 Acc: 0.7563\n",
            "Epoch: 13 eval Loss: 0.8939 Acc: 0.6562\n",
            "Epoch: 14 train Loss: 0.8588 Acc: 0.6000\n",
            "Epoch: 14 eval Loss: 1.0169 Acc: 0.5000\n",
            "Epoch: 15 train Loss: 0.8259 Acc: 0.6250\n",
            "Epoch: 15 eval Loss: 3.1782 Acc: 0.4688\n",
            "Epoch: 16 train Loss: 0.6073 Acc: 0.7313\n",
            "Epoch: 16 eval Loss: 2.3760 Acc: 0.5938\n",
            "Epoch: 17 train Loss: 0.5551 Acc: 0.7125\n",
            "Epoch: 17 eval Loss: 1.3158 Acc: 0.4062\n",
            "Epoch: 18 train Loss: 0.5282 Acc: 0.7250\n",
            "Epoch: 18 eval Loss: 0.9485 Acc: 0.5312\n",
            "Epoch: 19 train Loss: 0.4421 Acc: 0.7875\n",
            "Epoch: 19 eval Loss: 0.8338 Acc: 0.5938\n",
            "Epoch: 20 train Loss: 0.4562 Acc: 0.7938\n",
            "Epoch: 20 eval Loss: 0.7813 Acc: 0.6562\n",
            "Epoch: 21 train Loss: 0.3798 Acc: 0.8000\n",
            "Epoch: 21 eval Loss: 0.6641 Acc: 0.6875\n",
            "Epoch: 22 train Loss: 0.2887 Acc: 0.8625\n",
            "Epoch: 22 eval Loss: 0.6337 Acc: 0.7188\n",
            "Epoch: 23 train Loss: 0.2986 Acc: 0.8375\n",
            "Epoch: 23 eval Loss: 1.2177 Acc: 0.6250\n",
            "Epoch: 24 train Loss: 0.2889 Acc: 0.9000\n",
            "Epoch: 24 eval Loss: 0.8246 Acc: 0.6562\n",
            "Epoch: 25 train Loss: 0.2873 Acc: 0.8625\n",
            "Epoch: 25 eval Loss: 0.7380 Acc: 0.6562\n",
            "Epoch: 26 train Loss: 0.2538 Acc: 0.8625\n",
            "Epoch: 26 eval Loss: 0.7000 Acc: 0.6875\n",
            "Epoch: 27 train Loss: 0.2569 Acc: 0.8625\n",
            "Epoch: 27 eval Loss: 0.7179 Acc: 0.6875\n",
            "Epoch: 28 train Loss: 0.1947 Acc: 0.9062\n",
            "Epoch: 28 eval Loss: 0.7616 Acc: 0.6562\n",
            "Epoch: 29 train Loss: 0.2159 Acc: 0.8750\n",
            "Epoch: 29 eval Loss: 0.7865 Acc: 0.6562\n",
            "Epoch: 30 train Loss: 0.1950 Acc: 0.8875\n",
            "Epoch: 30 eval Loss: 0.8426 Acc: 0.6875\n",
            "Epoch: 31 train Loss: 0.1900 Acc: 0.9625\n",
            "Epoch: 31 eval Loss: 0.8268 Acc: 0.5625\n",
            "Epoch: 32 train Loss: 0.6927 Acc: 0.8500\n",
            "Epoch: 32 eval Loss: 3.9307 Acc: 0.5938\n",
            "Epoch: 33 train Loss: 0.3579 Acc: 0.9313\n",
            "Epoch: 33 eval Loss: 25.3925 Acc: 0.2812\n",
            "Epoch: 34 train Loss: 0.8056 Acc: 0.8313\n",
            "Epoch: 34 eval Loss: 18.6140 Acc: 0.2812\n",
            "Epoch: 35 train Loss: 0.3659 Acc: 0.8375\n",
            "Epoch: 35 eval Loss: 10.4122 Acc: 0.4688\n",
            "Epoch: 36 train Loss: 0.5271 Acc: 0.7875\n",
            "Epoch: 36 eval Loss: 7.1588 Acc: 0.5000\n",
            "Epoch: 37 train Loss: 0.5763 Acc: 0.7875\n",
            "Epoch: 37 eval Loss: 6.7019 Acc: 0.5312\n",
            "Epoch: 38 train Loss: 0.5815 Acc: 0.7313\n",
            "Epoch: 38 eval Loss: 5.6405 Acc: 0.5625\n",
            "Epoch: 39 train Loss: 0.3516 Acc: 0.8125\n",
            "Epoch: 39 eval Loss: 4.6158 Acc: 0.6250\n",
            "Epoch: 40 train Loss: 0.3341 Acc: 0.7625\n",
            "Epoch: 40 eval Loss: 2.9758 Acc: 0.5312\n",
            "Epoch: 41 train Loss: 0.2617 Acc: 0.8938\n",
            "Epoch: 41 eval Loss: 1.8656 Acc: 0.5625\n",
            "Epoch: 42 train Loss: 0.2439 Acc: 0.9625\n",
            "Epoch: 42 eval Loss: 1.5396 Acc: 0.5938\n",
            "Epoch: 43 train Loss: 0.2036 Acc: 0.9688\n",
            "Epoch: 43 eval Loss: 1.4833 Acc: 0.5938\n",
            "Epoch: 44 train Loss: 0.2012 Acc: 0.9688\n",
            "Epoch: 44 eval Loss: 1.4995 Acc: 0.5938\n",
            "Epoch: 45 train Loss: 0.1829 Acc: 0.9875\n",
            "Epoch: 45 eval Loss: 1.4905 Acc: 0.6250\n",
            "Epoch: 46 train Loss: 0.1595 Acc: 0.9875\n",
            "Epoch: 46 eval Loss: 1.4477 Acc: 0.6250\n",
            "Epoch: 47 train Loss: 0.1610 Acc: 0.9938\n",
            "Epoch: 47 eval Loss: 1.3897 Acc: 0.6562\n",
            "Epoch: 48 train Loss: 0.1378 Acc: 0.9875\n",
            "Epoch: 48 eval Loss: 1.3079 Acc: 0.6562\n",
            "Epoch: 49 train Loss: 0.1380 Acc: 0.9938\n",
            "Epoch: 49 eval Loss: 1.2707 Acc: 0.6562\n",
            "Fold 1 accuracy: 0.71875 achieved in epoch 22\n",
            "Train:  [  0   1   2   3   4   7   9  11  12  13  14  15  16  17  18  19  20  21\n",
            "  22  23  24  25  26  28  30  31  32  33  34  35  36  37  38  40  41  43\n",
            "  44  46  47  49  50  51  52  53  54  55  56  57  58  59  60  61  63  64\n",
            "  65  66  67  68  70  71  72  73  75  76  77  78  80  81  82  83  84  85\n",
            "  86  87  88  89  90  91  92  93  94  95  96  97  99 100 101 103 104 105\n",
            " 106 107 109 111 112 113 115 116 118 119 120 121 122 123 124 125 127 129\n",
            " 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147\n",
            " 148 149 151 152 154 155 158 159 160 162 163 164 165 166 168 169 170 171\n",
            " 172 173 174 175 176 177 179 180 181 182 183 185 187 188 189 191] Validation:  [  5   6   8  10  27  29  39  42  45  48  62  69  74  79  98 102 108 110\n",
            " 114 117 126 128 150 153 156 157 161 167 178 184 186 190]\n",
            "Epoch: 0 train Loss: 42.1367 Acc: 0.3563\n",
            "Epoch: 0 eval Loss: 9.2232 Acc: 0.3125\n",
            "Epoch: 1 train Loss: 1.2854 Acc: 0.2313\n",
            "Epoch: 1 eval Loss: 1.1424 Acc: 0.4688\n",
            "Epoch: 2 train Loss: 1.0790 Acc: 0.3438\n",
            "Epoch: 2 eval Loss: 7.1466 Acc: 0.3438\n",
            "Epoch: 3 train Loss: 1.0749 Acc: 0.4688\n",
            "Epoch: 3 eval Loss: 3.7514 Acc: 0.3438\n",
            "Epoch: 4 train Loss: 1.0680 Acc: 0.4938\n",
            "Epoch: 4 eval Loss: 2.0684 Acc: 0.3750\n",
            "Epoch: 5 train Loss: 1.0352 Acc: 0.5938\n",
            "Epoch: 5 eval Loss: 1.1840 Acc: 0.3750\n",
            "Epoch: 6 train Loss: 0.9871 Acc: 0.6000\n",
            "Epoch: 6 eval Loss: 1.0338 Acc: 0.4062\n",
            "Epoch: 7 train Loss: 0.9329 Acc: 0.5875\n",
            "Epoch: 7 eval Loss: 0.9657 Acc: 0.4375\n",
            "Epoch: 8 train Loss: 0.8567 Acc: 0.6313\n",
            "Epoch: 8 eval Loss: 1.0210 Acc: 0.4375\n",
            "Epoch: 9 train Loss: 0.7831 Acc: 0.6938\n",
            "Epoch: 9 eval Loss: 1.0184 Acc: 0.5312\n",
            "Epoch: 10 train Loss: 0.6901 Acc: 0.7438\n",
            "Epoch: 10 eval Loss: 0.9990 Acc: 0.4688\n",
            "Epoch: 11 train Loss: 0.6098 Acc: 0.7438\n",
            "Epoch: 11 eval Loss: 1.1611 Acc: 0.5625\n",
            "Epoch: 12 train Loss: 0.5144 Acc: 0.7812\n",
            "Epoch: 12 eval Loss: 0.9916 Acc: 0.5938\n",
            "Epoch: 13 train Loss: 0.4200 Acc: 0.8313\n",
            "Epoch: 13 eval Loss: 1.0832 Acc: 0.5000\n",
            "Epoch: 14 train Loss: 0.3160 Acc: 0.8813\n",
            "Epoch: 14 eval Loss: 1.0364 Acc: 0.5625\n",
            "Epoch: 15 train Loss: 0.3463 Acc: 0.8938\n",
            "Epoch: 15 eval Loss: 1.3733 Acc: 0.6562\n",
            "Epoch: 16 train Loss: 0.2964 Acc: 0.8875\n",
            "Epoch: 16 eval Loss: 0.9404 Acc: 0.6250\n",
            "Epoch: 17 train Loss: 0.2621 Acc: 0.9125\n",
            "Epoch: 17 eval Loss: 0.9507 Acc: 0.5625\n",
            "Epoch: 18 train Loss: 0.3009 Acc: 0.9000\n",
            "Epoch: 18 eval Loss: 1.2884 Acc: 0.6875\n",
            "Epoch: 19 train Loss: 0.2186 Acc: 0.9250\n",
            "Epoch: 19 eval Loss: 2.2540 Acc: 0.6875\n",
            "Epoch: 20 train Loss: 0.1954 Acc: 0.9250\n",
            "Epoch: 20 eval Loss: 1.7792 Acc: 0.7188\n",
            "Epoch: 21 train Loss: 0.1660 Acc: 0.9375\n",
            "Epoch: 21 eval Loss: 1.6846 Acc: 0.7188\n",
            "Epoch: 22 train Loss: 0.1423 Acc: 0.9500\n",
            "Epoch: 22 eval Loss: 2.3716 Acc: 0.6875\n",
            "Epoch: 23 train Loss: 0.1337 Acc: 0.9438\n",
            "Epoch: 23 eval Loss: 2.0180 Acc: 0.6875\n",
            "Epoch: 24 train Loss: 0.1068 Acc: 0.9500\n",
            "Epoch: 24 eval Loss: 1.9430 Acc: 0.6875\n",
            "Epoch: 25 train Loss: 0.1257 Acc: 0.9438\n",
            "Epoch: 25 eval Loss: 2.4842 Acc: 0.6875\n",
            "Epoch: 26 train Loss: 0.1145 Acc: 0.9500\n",
            "Epoch: 26 eval Loss: 1.9918 Acc: 0.6875\n",
            "Epoch: 27 train Loss: 0.1275 Acc: 0.9625\n",
            "Epoch: 27 eval Loss: 2.5968 Acc: 0.7188\n",
            "Epoch: 28 train Loss: 0.1232 Acc: 0.9563\n",
            "Epoch: 28 eval Loss: 3.0739 Acc: 0.6562\n",
            "Epoch: 29 train Loss: 0.1122 Acc: 0.9688\n",
            "Epoch: 29 eval Loss: 2.4376 Acc: 0.6875\n",
            "Epoch: 30 train Loss: 0.1019 Acc: 0.9625\n",
            "Epoch: 30 eval Loss: 2.7911 Acc: 0.6562\n",
            "Epoch: 31 train Loss: 0.0988 Acc: 0.9688\n",
            "Epoch: 31 eval Loss: 3.2865 Acc: 0.6562\n",
            "Epoch: 32 train Loss: 0.1248 Acc: 0.9500\n",
            "Epoch: 32 eval Loss: 4.6439 Acc: 0.6562\n",
            "Epoch: 33 train Loss: 0.2293 Acc: 0.9250\n",
            "Epoch: 33 eval Loss: 4.2970 Acc: 0.6250\n",
            "Epoch: 34 train Loss: 0.2606 Acc: 0.9062\n",
            "Epoch: 34 eval Loss: 5.6336 Acc: 0.5625\n",
            "Epoch: 35 train Loss: 0.2761 Acc: 0.8688\n",
            "Epoch: 35 eval Loss: 6.0128 Acc: 0.5938\n",
            "Epoch: 36 train Loss: 0.2068 Acc: 0.9188\n",
            "Epoch: 36 eval Loss: 2.7394 Acc: 0.7188\n",
            "Epoch: 37 train Loss: 0.2362 Acc: 0.9250\n",
            "Epoch: 37 eval Loss: 2.4708 Acc: 0.7188\n",
            "Epoch: 38 train Loss: 0.2623 Acc: 0.9125\n",
            "Epoch: 38 eval Loss: 2.7432 Acc: 0.6875\n",
            "Epoch: 39 train Loss: 0.1694 Acc: 0.9250\n",
            "Epoch: 39 eval Loss: 2.4802 Acc: 0.6875\n",
            "Epoch: 40 train Loss: 0.1629 Acc: 0.9313\n",
            "Epoch: 40 eval Loss: 2.3924 Acc: 0.6562\n",
            "Epoch: 41 train Loss: 0.1358 Acc: 0.9375\n",
            "Epoch: 41 eval Loss: 2.3355 Acc: 0.7188\n",
            "Epoch: 42 train Loss: 0.1435 Acc: 0.9250\n",
            "Epoch: 42 eval Loss: 2.4151 Acc: 0.7500\n",
            "Epoch: 43 train Loss: 0.1338 Acc: 0.9438\n",
            "Epoch: 43 eval Loss: 2.8806 Acc: 0.8125\n",
            "Epoch: 44 train Loss: 0.0978 Acc: 0.9500\n",
            "Epoch: 44 eval Loss: 3.7951 Acc: 0.7188\n",
            "Epoch: 45 train Loss: 0.0864 Acc: 0.9563\n",
            "Epoch: 45 eval Loss: 4.2702 Acc: 0.7188\n",
            "Epoch: 46 train Loss: 0.0858 Acc: 0.9625\n",
            "Epoch: 46 eval Loss: 3.7582 Acc: 0.7188\n",
            "Epoch: 47 train Loss: 0.0872 Acc: 0.9563\n",
            "Epoch: 47 eval Loss: 3.2507 Acc: 0.7500\n",
            "Epoch: 48 train Loss: 0.0844 Acc: 0.9563\n",
            "Epoch: 48 eval Loss: 2.9034 Acc: 0.7500\n",
            "Epoch: 49 train Loss: 0.0800 Acc: 0.9563\n",
            "Epoch: 49 eval Loss: 2.8125 Acc: 0.7500\n",
            "Fold 2 accuracy: 0.8125 achieved in epoch 43\n",
            "Train:  [  0   1   2   3   4   5   6   8   9  10  11  12  13  14  16  17  18  19\n",
            "  20  21  23  24  26  27  28  29  30  31  32  34  36  37  38  39  40  41\n",
            "  42  43  45  46  47  48  50  51  54  55  56  57  58  59  60  61  62  65\n",
            "  66  67  68  69  70  71  72  73  74  75  76  78  79  81  82  83  84  85\n",
            "  86  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104\n",
            " 105 106 108 110 111 113 114 116 117 118 119 120 121 122 124 125 126 128\n",
            " 129 130 131 132 133 134 135 137 138 141 142 143 144 145 146 147 148 149\n",
            " 150 151 153 156 157 158 160 161 162 163 164 165 166 167 168 169 171 172\n",
            " 173 176 177 178 179 181 182 183 184 185 186 187 188 189 190 191] Validation:  [  7  15  22  25  33  35  44  49  52  53  63  64  77  80  87 107 109 112\n",
            " 115 123 127 136 139 140 152 154 155 159 170 174 175 180]\n",
            "Epoch: 0 train Loss: 39.4395 Acc: 0.2375\n",
            "Epoch: 0 eval Loss: 1.7771 Acc: 0.3438\n",
            "Epoch: 1 train Loss: 1.2746 Acc: 0.3375\n",
            "Epoch: 1 eval Loss: 1.1296 Acc: 0.3750\n",
            "Epoch: 2 train Loss: 1.1117 Acc: 0.2313\n",
            "Epoch: 2 eval Loss: 9.2455 Acc: 0.3438\n",
            "Epoch: 3 train Loss: 1.1007 Acc: 0.3063\n",
            "Epoch: 3 eval Loss: 2.9400 Acc: 0.3438\n",
            "Epoch: 4 train Loss: 1.0868 Acc: 0.4500\n",
            "Epoch: 4 eval Loss: 1.4973 Acc: 0.3438\n",
            "Epoch: 5 train Loss: 1.0785 Acc: 0.4438\n",
            "Epoch: 5 eval Loss: 1.1273 Acc: 0.3750\n",
            "Epoch: 6 train Loss: 1.0688 Acc: 0.4500\n",
            "Epoch: 6 eval Loss: 1.0886 Acc: 0.4688\n",
            "Epoch: 7 train Loss: 1.0573 Acc: 0.4062\n",
            "Epoch: 7 eval Loss: 1.0601 Acc: 0.4375\n",
            "Epoch: 8 train Loss: 1.0319 Acc: 0.4750\n",
            "Epoch: 8 eval Loss: 1.0952 Acc: 0.4375\n",
            "Epoch: 9 train Loss: 0.9782 Acc: 0.5312\n",
            "Epoch: 9 eval Loss: 1.0833 Acc: 0.4688\n",
            "Epoch: 10 train Loss: 0.8970 Acc: 0.5563\n",
            "Epoch: 10 eval Loss: 0.9748 Acc: 0.5312\n",
            "Epoch: 11 train Loss: 0.9139 Acc: 0.5687\n",
            "Epoch: 11 eval Loss: 0.9270 Acc: 0.4688\n",
            "Epoch: 12 train Loss: 0.8374 Acc: 0.5375\n",
            "Epoch: 12 eval Loss: 1.0363 Acc: 0.4688\n",
            "Epoch: 13 train Loss: 0.8200 Acc: 0.5500\n",
            "Epoch: 13 eval Loss: 0.8991 Acc: 0.5000\n",
            "Epoch: 14 train Loss: 0.6779 Acc: 0.6625\n",
            "Epoch: 14 eval Loss: 0.9104 Acc: 0.6250\n",
            "Epoch: 15 train Loss: 0.6437 Acc: 0.6688\n",
            "Epoch: 15 eval Loss: 0.9832 Acc: 0.6875\n",
            "Epoch: 16 train Loss: 0.5527 Acc: 0.7250\n",
            "Epoch: 16 eval Loss: 1.4368 Acc: 0.5312\n",
            "Epoch: 17 train Loss: 0.5550 Acc: 0.7313\n",
            "Epoch: 17 eval Loss: 1.1246 Acc: 0.5312\n",
            "Epoch: 18 train Loss: 0.4590 Acc: 0.7625\n",
            "Epoch: 18 eval Loss: 0.9157 Acc: 0.5312\n",
            "Epoch: 19 train Loss: 0.4485 Acc: 0.7750\n",
            "Epoch: 19 eval Loss: 0.9439 Acc: 0.5000\n",
            "Epoch: 20 train Loss: 0.3900 Acc: 0.8125\n",
            "Epoch: 20 eval Loss: 1.0895 Acc: 0.5000\n",
            "Epoch: 21 train Loss: 0.3953 Acc: 0.8250\n",
            "Epoch: 21 eval Loss: 1.0231 Acc: 0.5625\n",
            "Epoch: 22 train Loss: 0.4936 Acc: 0.8250\n",
            "Epoch: 22 eval Loss: 3.0753 Acc: 0.6562\n",
            "Epoch: 23 train Loss: 0.4916 Acc: 0.7563\n",
            "Epoch: 23 eval Loss: 1.2977 Acc: 0.5938\n",
            "Epoch: 24 train Loss: 0.4759 Acc: 0.8750\n",
            "Epoch: 24 eval Loss: 1.3134 Acc: 0.4375\n",
            "Epoch: 25 train Loss: 0.6095 Acc: 0.7938\n",
            "Epoch: 25 eval Loss: 0.8349 Acc: 0.5625\n",
            "Epoch: 26 train Loss: 0.5988 Acc: 0.7188\n",
            "Epoch: 26 eval Loss: 9.8830 Acc: 0.5000\n",
            "Epoch: 27 train Loss: 0.7157 Acc: 0.7000\n",
            "Epoch: 27 eval Loss: 5.1308 Acc: 0.6250\n",
            "Epoch: 28 train Loss: 0.5523 Acc: 0.7500\n",
            "Epoch: 28 eval Loss: 2.9733 Acc: 0.6250\n",
            "Epoch: 29 train Loss: 0.4407 Acc: 0.8188\n",
            "Epoch: 29 eval Loss: 1.6206 Acc: 0.6875\n",
            "Epoch: 30 train Loss: 0.3929 Acc: 0.8375\n",
            "Epoch: 30 eval Loss: 0.9243 Acc: 0.6875\n",
            "Epoch: 31 train Loss: 0.3112 Acc: 0.9375\n",
            "Epoch: 31 eval Loss: 0.8052 Acc: 0.5312\n",
            "Epoch: 32 train Loss: 0.2502 Acc: 0.9250\n",
            "Epoch: 32 eval Loss: 0.9785 Acc: 0.5938\n",
            "Epoch: 33 train Loss: 0.2222 Acc: 0.9125\n",
            "Epoch: 33 eval Loss: 1.1049 Acc: 0.5938\n",
            "Epoch: 34 train Loss: 0.1747 Acc: 0.9625\n",
            "Epoch: 34 eval Loss: 1.1843 Acc: 0.6562\n",
            "Epoch: 35 train Loss: 0.1682 Acc: 0.9813\n",
            "Epoch: 35 eval Loss: 1.9336 Acc: 0.6562\n",
            "Epoch: 36 train Loss: 0.1366 Acc: 0.9750\n",
            "Epoch: 36 eval Loss: 2.1701 Acc: 0.7188\n",
            "Epoch: 37 train Loss: 0.1728 Acc: 0.9625\n",
            "Epoch: 37 eval Loss: 1.5331 Acc: 0.7188\n",
            "Epoch: 38 train Loss: 0.1579 Acc: 0.9438\n",
            "Epoch: 38 eval Loss: 1.3148 Acc: 0.7500\n",
            "Epoch: 39 train Loss: 0.1165 Acc: 0.9813\n",
            "Epoch: 39 eval Loss: 1.2959 Acc: 0.7188\n",
            "Epoch: 40 train Loss: 0.1108 Acc: 0.9813\n",
            "Epoch: 40 eval Loss: 1.3808 Acc: 0.6875\n",
            "Epoch: 41 train Loss: 0.0786 Acc: 1.0000\n",
            "Epoch: 41 eval Loss: 1.5289 Acc: 0.7188\n",
            "Epoch: 42 train Loss: 0.0791 Acc: 1.0000\n",
            "Epoch: 42 eval Loss: 1.6527 Acc: 0.6562\n",
            "Epoch: 43 train Loss: 0.0723 Acc: 1.0000\n",
            "Epoch: 43 eval Loss: 1.7831 Acc: 0.6562\n",
            "Epoch: 44 train Loss: 0.0981 Acc: 0.9813\n",
            "Epoch: 44 eval Loss: 1.8233 Acc: 0.5938\n",
            "Epoch: 45 train Loss: 0.0819 Acc: 0.9813\n",
            "Epoch: 45 eval Loss: 1.5501 Acc: 0.6562\n",
            "Epoch: 46 train Loss: 0.0624 Acc: 0.9938\n",
            "Epoch: 46 eval Loss: 1.9387 Acc: 0.6562\n",
            "Epoch: 47 train Loss: 0.0608 Acc: 1.0000\n",
            "Epoch: 47 eval Loss: 1.6937 Acc: 0.6875\n",
            "Epoch: 48 train Loss: 0.0663 Acc: 0.9938\n",
            "Epoch: 48 eval Loss: 1.7529 Acc: 0.7188\n",
            "Epoch: 49 train Loss: 0.0506 Acc: 1.0000\n",
            "Epoch: 49 eval Loss: 1.7530 Acc: 0.7188\n",
            "Fold 3 accuracy: 0.75 achieved in epoch 38\n",
            "Train:  [  0   1   3   5   6   7   8   9  10  11  12  14  15  16  17  18  22  23\n",
            "  24  25  26  27  28  29  30  33  34  35  36  38  39  40  41  42  43  44\n",
            "  45  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63\n",
            "  64  65  66  67  68  69  70  71  72  73  74  77  78  79  80  82  83  84\n",
            "  85  87  88  91  92  93  94  96  97  98 100 101 102 103 104 106 107 108\n",
            " 109 110 111 112 114 115 116 117 118 119 120 122 123 124 125 126 127 128\n",
            " 129 130 131 133 134 136 137 138 139 140 141 142 144 146 147 148 149 150\n",
            " 151 152 153 154 155 156 157 158 159 161 163 165 167 168 169 170 172 174\n",
            " 175 176 177 178 179 180 181 182 183 184 185 186 187 189 190 191] Validation:  [  2   4  13  19  20  21  31  32  37  46  75  76  81  86  89  90  95  99\n",
            " 105 113 121 132 135 143 145 160 162 164 166 171 173 188]\n",
            "Epoch: 0 train Loss: 49.1059 Acc: 0.2750\n",
            "Epoch: 0 eval Loss: 6.5638 Acc: 0.3438\n",
            "Epoch: 1 train Loss: 1.2485 Acc: 0.3375\n",
            "Epoch: 1 eval Loss: 19.9052 Acc: 0.3438\n",
            "Epoch: 2 train Loss: 1.0746 Acc: 0.4375\n",
            "Epoch: 2 eval Loss: 87.5029 Acc: 0.3438\n",
            "Epoch: 3 train Loss: 1.0220 Acc: 0.5375\n",
            "Epoch: 3 eval Loss: 77.6290 Acc: 0.3438\n",
            "Epoch: 4 train Loss: 1.0226 Acc: 0.5438\n",
            "Epoch: 4 eval Loss: 25.0202 Acc: 0.3438\n",
            "Epoch: 5 train Loss: 0.9689 Acc: 0.5500\n",
            "Epoch: 5 eval Loss: 8.2350 Acc: 0.3438\n",
            "Epoch: 6 train Loss: 0.8888 Acc: 0.6250\n",
            "Epoch: 6 eval Loss: 2.9789 Acc: 0.4688\n",
            "Epoch: 7 train Loss: 0.7955 Acc: 0.6813\n",
            "Epoch: 7 eval Loss: 2.0259 Acc: 0.5000\n",
            "Epoch: 8 train Loss: 0.7110 Acc: 0.7625\n",
            "Epoch: 8 eval Loss: 1.7628 Acc: 0.4688\n",
            "Epoch: 9 train Loss: 0.5780 Acc: 0.7938\n",
            "Epoch: 9 eval Loss: 1.0271 Acc: 0.6250\n",
            "Epoch: 10 train Loss: 0.4153 Acc: 0.8125\n",
            "Epoch: 10 eval Loss: 1.4028 Acc: 0.5625\n",
            "Epoch: 11 train Loss: 0.3442 Acc: 0.8313\n",
            "Epoch: 11 eval Loss: 0.7700 Acc: 0.6875\n",
            "Epoch: 12 train Loss: 0.5650 Acc: 0.8188\n",
            "Epoch: 12 eval Loss: 14.3184 Acc: 0.3125\n",
            "Epoch: 13 train Loss: 1.0617 Acc: 0.6438\n",
            "Epoch: 13 eval Loss: 6.7346 Acc: 0.4688\n",
            "Epoch: 14 train Loss: 0.6042 Acc: 0.8188\n",
            "Epoch: 14 eval Loss: 0.8139 Acc: 0.5625\n",
            "Epoch: 15 train Loss: 0.5459 Acc: 0.8063\n",
            "Epoch: 15 eval Loss: 4.9737 Acc: 0.3438\n",
            "Epoch: 16 train Loss: 0.4417 Acc: 0.8375\n",
            "Epoch: 16 eval Loss: 7.8444 Acc: 0.2500\n",
            "Epoch: 17 train Loss: 0.3566 Acc: 0.8563\n",
            "Epoch: 17 eval Loss: 1.9296 Acc: 0.4688\n",
            "Epoch: 18 train Loss: 0.3408 Acc: 0.9062\n",
            "Epoch: 18 eval Loss: 1.0870 Acc: 0.6250\n",
            "Epoch: 19 train Loss: 0.2713 Acc: 0.9500\n",
            "Epoch: 19 eval Loss: 0.9390 Acc: 0.5938\n",
            "Epoch: 20 train Loss: 0.2413 Acc: 0.9188\n",
            "Epoch: 20 eval Loss: 0.8319 Acc: 0.5938\n",
            "Epoch: 21 train Loss: 0.2197 Acc: 0.9375\n",
            "Epoch: 21 eval Loss: 0.9038 Acc: 0.6562\n",
            "Epoch: 22 train Loss: 0.1920 Acc: 0.9563\n",
            "Epoch: 22 eval Loss: 1.1237 Acc: 0.5938\n",
            "Epoch: 23 train Loss: 0.1639 Acc: 0.9625\n",
            "Epoch: 23 eval Loss: 1.6123 Acc: 0.4375\n",
            "Epoch: 24 train Loss: 0.1469 Acc: 0.9688\n",
            "Epoch: 24 eval Loss: 0.8970 Acc: 0.5312\n",
            "Epoch: 25 train Loss: 0.1440 Acc: 0.9563\n",
            "Epoch: 25 eval Loss: 2.3571 Acc: 0.4375\n",
            "Epoch: 26 train Loss: 0.1596 Acc: 0.9625\n",
            "Epoch: 26 eval Loss: 1.1693 Acc: 0.5312\n",
            "Epoch: 27 train Loss: 0.1627 Acc: 0.9563\n",
            "Epoch: 27 eval Loss: 1.1138 Acc: 0.5625\n",
            "Epoch: 28 train Loss: 0.1468 Acc: 0.9625\n",
            "Epoch: 28 eval Loss: 1.1551 Acc: 0.5938\n",
            "Epoch: 29 train Loss: 0.2036 Acc: 0.9313\n",
            "Epoch: 29 eval Loss: 1.2729 Acc: 0.5312\n",
            "Epoch: 30 train Loss: 0.1549 Acc: 0.9625\n",
            "Epoch: 30 eval Loss: 2.3417 Acc: 0.4375\n",
            "Epoch: 31 train Loss: 0.1786 Acc: 0.9438\n",
            "Epoch: 31 eval Loss: 4.1059 Acc: 0.4062\n",
            "Epoch: 32 train Loss: 0.2196 Acc: 0.9563\n",
            "Epoch: 32 eval Loss: 2.7838 Acc: 0.4375\n",
            "Epoch: 33 train Loss: 0.1831 Acc: 0.9500\n",
            "Epoch: 33 eval Loss: 2.4662 Acc: 0.4688\n",
            "Epoch: 34 train Loss: 0.1451 Acc: 0.9625\n",
            "Epoch: 34 eval Loss: 3.1224 Acc: 0.4688\n",
            "Epoch: 35 train Loss: 0.1694 Acc: 0.9438\n",
            "Epoch: 35 eval Loss: 1.5187 Acc: 0.5000\n",
            "Epoch: 36 train Loss: 0.1400 Acc: 0.9625\n",
            "Epoch: 36 eval Loss: 1.3880 Acc: 0.5000\n",
            "Epoch: 37 train Loss: 0.1239 Acc: 0.9813\n",
            "Epoch: 37 eval Loss: 1.5958 Acc: 0.4688\n",
            "Epoch: 38 train Loss: 0.1101 Acc: 0.9813\n",
            "Epoch: 38 eval Loss: 1.7390 Acc: 0.4688\n",
            "Epoch: 39 train Loss: 0.1209 Acc: 0.9813\n",
            "Epoch: 39 eval Loss: 1.8748 Acc: 0.5000\n",
            "Epoch: 40 train Loss: 0.1127 Acc: 0.9813\n",
            "Epoch: 40 eval Loss: 2.0362 Acc: 0.5000\n",
            "Epoch: 41 train Loss: 0.0873 Acc: 0.9875\n",
            "Epoch: 41 eval Loss: 2.1421 Acc: 0.5000\n",
            "Epoch: 42 train Loss: 0.0852 Acc: 0.9813\n",
            "Epoch: 42 eval Loss: 2.2199 Acc: 0.4688\n",
            "Epoch: 43 train Loss: 0.0833 Acc: 0.9875\n",
            "Epoch: 43 eval Loss: 2.2798 Acc: 0.4688\n",
            "Epoch: 44 train Loss: 0.0760 Acc: 0.9875\n",
            "Epoch: 44 eval Loss: 2.3416 Acc: 0.5000\n",
            "Epoch: 45 train Loss: 0.0739 Acc: 0.9875\n",
            "Epoch: 45 eval Loss: 2.3562 Acc: 0.5000\n",
            "Epoch: 46 train Loss: 0.0745 Acc: 0.9875\n",
            "Epoch: 46 eval Loss: 2.4089 Acc: 0.4688\n",
            "Epoch: 47 train Loss: 0.0738 Acc: 0.9875\n",
            "Epoch: 47 eval Loss: 2.4412 Acc: 0.4688\n",
            "Epoch: 48 train Loss: 0.0693 Acc: 0.9875\n",
            "Epoch: 48 eval Loss: 2.4678 Acc: 0.4688\n",
            "Epoch: 49 train Loss: 0.0799 Acc: 0.9875\n",
            "Epoch: 49 eval Loss: 2.4347 Acc: 0.4688\n",
            "Fold 4 accuracy: 0.6875 achieved in epoch 11\n",
            "Train:  [  0   2   4   5   6   7   8   9  10  11  13  14  15  16  17  19  20  21\n",
            "  22  23  24  25  26  27  28  29  31  32  33  34  35  36  37  38  39  41\n",
            "  42  43  44  45  46  47  48  49  52  53  54  55  56  57  58  60  62  63\n",
            "  64  65  66  68  69  70  72  73  74  75  76  77  78  79  80  81  82  83\n",
            "  85  86  87  88  89  90  91  92  95  96  98  99 100 102 103 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 119 120 121 123 125 126 127 128\n",
            " 129 130 132 133 134 135 136 139 140 141 142 143 145 147 148 150 151 152\n",
            " 153 154 155 156 157 158 159 160 161 162 164 166 167 168 169 170 171 172\n",
            " 173 174 175 177 178 179 180 181 182 183 184 186 187 188 190 191] Validation:  [  1   3  12  18  30  40  50  51  59  61  67  71  84  93  94  97 101 104\n",
            " 118 122 124 131 137 138 144 146 149 163 165 176 185 189]\n",
            "Epoch: 0 train Loss: 34.5449 Acc: 0.2625\n",
            "Epoch: 0 eval Loss: 13.7969 Acc: 0.3438\n",
            "Epoch: 1 train Loss: 1.2721 Acc: 0.3438\n",
            "Epoch: 1 eval Loss: 25.4930 Acc: 0.3438\n",
            "Epoch: 2 train Loss: 1.0765 Acc: 0.4500\n",
            "Epoch: 2 eval Loss: 41.3772 Acc: 0.5312\n",
            "Epoch: 3 train Loss: 1.0769 Acc: 0.5250\n",
            "Epoch: 3 eval Loss: 25.9328 Acc: 0.3750\n",
            "Epoch: 4 train Loss: 1.0707 Acc: 0.5563\n",
            "Epoch: 4 eval Loss: 15.7318 Acc: 0.3750\n",
            "Epoch: 5 train Loss: 1.0457 Acc: 0.5813\n",
            "Epoch: 5 eval Loss: 23.9429 Acc: 0.3750\n",
            "Epoch: 6 train Loss: 1.0102 Acc: 0.5875\n",
            "Epoch: 6 eval Loss: 10.6411 Acc: 0.4375\n",
            "Epoch: 7 train Loss: 0.9426 Acc: 0.6375\n",
            "Epoch: 7 eval Loss: 2.4417 Acc: 0.6250\n",
            "Epoch: 8 train Loss: 0.8707 Acc: 0.6875\n",
            "Epoch: 8 eval Loss: 2.0122 Acc: 0.7188\n",
            "Epoch: 9 train Loss: 0.7852 Acc: 0.7125\n",
            "Epoch: 9 eval Loss: 0.8856 Acc: 0.7188\n",
            "Epoch: 10 train Loss: 0.7004 Acc: 0.7313\n",
            "Epoch: 10 eval Loss: 0.7411 Acc: 0.7188\n",
            "Epoch: 11 train Loss: 0.5961 Acc: 0.7563\n",
            "Epoch: 11 eval Loss: 0.6390 Acc: 0.8438\n",
            "Epoch: 12 train Loss: 0.5068 Acc: 0.7250\n",
            "Epoch: 12 eval Loss: 0.6968 Acc: 0.7500\n",
            "Epoch: 13 train Loss: 0.5051 Acc: 0.7250\n",
            "Epoch: 13 eval Loss: 0.7423 Acc: 0.7500\n",
            "Epoch: 14 train Loss: 0.4500 Acc: 0.7750\n",
            "Epoch: 14 eval Loss: 1.2441 Acc: 0.7500\n",
            "Epoch: 15 train Loss: 0.4812 Acc: 0.7563\n",
            "Epoch: 15 eval Loss: 1.0182 Acc: 0.6875\n",
            "Epoch: 16 train Loss: 1.4544 Acc: 0.6625\n",
            "Epoch: 16 eval Loss: 2.5679 Acc: 0.5312\n",
            "Epoch: 17 train Loss: 0.9411 Acc: 0.6313\n",
            "Epoch: 17 eval Loss: 3.7824 Acc: 0.5312\n",
            "Epoch: 18 train Loss: 0.8045 Acc: 0.6000\n",
            "Epoch: 18 eval Loss: 2.5106 Acc: 0.5000\n",
            "Epoch: 19 train Loss: 0.7175 Acc: 0.6938\n",
            "Epoch: 19 eval Loss: 1.7527 Acc: 0.6250\n",
            "Epoch: 20 train Loss: 0.6799 Acc: 0.7375\n",
            "Epoch: 20 eval Loss: 1.3648 Acc: 0.7188\n",
            "Epoch: 21 train Loss: 0.6497 Acc: 0.6938\n",
            "Epoch: 21 eval Loss: 1.2605 Acc: 0.7188\n",
            "Epoch: 22 train Loss: 0.5539 Acc: 0.7500\n",
            "Epoch: 22 eval Loss: 1.6308 Acc: 0.7500\n",
            "Epoch: 23 train Loss: 0.5080 Acc: 0.7625\n",
            "Epoch: 23 eval Loss: 1.7191 Acc: 0.7188\n",
            "Epoch: 24 train Loss: 0.4886 Acc: 0.7625\n",
            "Epoch: 24 eval Loss: 1.6378 Acc: 0.7500\n",
            "Epoch: 25 train Loss: 0.4433 Acc: 0.7688\n",
            "Epoch: 25 eval Loss: 1.5036 Acc: 0.7500\n",
            "Epoch: 26 train Loss: 0.4097 Acc: 0.8125\n",
            "Epoch: 26 eval Loss: 1.5816 Acc: 0.7812\n",
            "Epoch: 27 train Loss: 0.4015 Acc: 0.8563\n",
            "Epoch: 27 eval Loss: 1.5917 Acc: 0.8125\n",
            "Epoch: 28 train Loss: 0.4165 Acc: 0.8063\n",
            "Epoch: 28 eval Loss: 1.0167 Acc: 0.6875\n",
            "Epoch: 29 train Loss: 0.3806 Acc: 0.8375\n",
            "Epoch: 29 eval Loss: 0.9319 Acc: 0.5625\n",
            "Epoch: 30 train Loss: 0.3136 Acc: 0.8688\n",
            "Epoch: 30 eval Loss: 0.9959 Acc: 0.6875\n",
            "Epoch: 31 train Loss: 0.2696 Acc: 0.9125\n",
            "Epoch: 31 eval Loss: 1.7184 Acc: 0.5625\n",
            "Epoch: 32 train Loss: 0.3877 Acc: 0.8750\n",
            "Epoch: 32 eval Loss: 0.9276 Acc: 0.6562\n",
            "Epoch: 33 train Loss: 0.4754 Acc: 0.8250\n",
            "Epoch: 33 eval Loss: 1.0767 Acc: 0.3438\n",
            "Epoch: 34 train Loss: 0.5377 Acc: 0.7625\n",
            "Epoch: 34 eval Loss: 0.9285 Acc: 0.6250\n",
            "Epoch: 35 train Loss: 0.4535 Acc: 0.7625\n",
            "Epoch: 35 eval Loss: 0.9753 Acc: 0.6875\n",
            "Epoch: 36 train Loss: 0.4232 Acc: 0.8125\n",
            "Epoch: 36 eval Loss: 1.5670 Acc: 0.6875\n",
            "Epoch: 37 train Loss: 0.3772 Acc: 0.8250\n",
            "Epoch: 37 eval Loss: 1.9537 Acc: 0.6875\n",
            "Epoch: 38 train Loss: 0.3357 Acc: 0.8688\n",
            "Epoch: 38 eval Loss: 2.1273 Acc: 0.7188\n",
            "Epoch: 39 train Loss: 0.3293 Acc: 0.8750\n",
            "Epoch: 39 eval Loss: 2.0377 Acc: 0.7188\n",
            "Epoch: 40 train Loss: 0.2842 Acc: 0.9062\n",
            "Epoch: 40 eval Loss: 1.6928 Acc: 0.7500\n",
            "Epoch: 41 train Loss: 0.2549 Acc: 0.8938\n",
            "Epoch: 41 eval Loss: 1.5343 Acc: 0.7188\n",
            "Epoch: 42 train Loss: 0.2411 Acc: 0.9000\n",
            "Epoch: 42 eval Loss: 1.5366 Acc: 0.7188\n",
            "Epoch: 43 train Loss: 0.2513 Acc: 0.9000\n",
            "Epoch: 43 eval Loss: 1.3942 Acc: 0.7500\n",
            "Epoch: 44 train Loss: 0.2146 Acc: 0.9125\n",
            "Epoch: 44 eval Loss: 1.3949 Acc: 0.7500\n",
            "Epoch: 45 train Loss: 0.1964 Acc: 0.9250\n",
            "Epoch: 45 eval Loss: 1.3418 Acc: 0.7500\n",
            "Epoch: 46 train Loss: 0.2082 Acc: 0.9188\n",
            "Epoch: 46 eval Loss: 1.3447 Acc: 0.7188\n",
            "Epoch: 47 train Loss: 0.1887 Acc: 0.9375\n",
            "Epoch: 47 eval Loss: 1.2439 Acc: 0.7188\n",
            "Epoch: 48 train Loss: 0.1509 Acc: 0.9563\n",
            "Epoch: 48 eval Loss: 1.3420 Acc: 0.6875\n",
            "Epoch: 49 train Loss: 0.1075 Acc: 0.9625\n",
            "Epoch: 49 eval Loss: 1.6025 Acc: 0.6250\n",
            "Fold 5 accuracy: 0.84375 achieved in epoch 11\n",
            "Finished Training, took 39m 43s\n",
            "Average accuracy: 0.7135416666666666\n",
            "Average epoch: 22.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "avg. accuracies (step size 7, gamma 0.1)\n",
        "- 50 epochs, batch size 32, lr 0.001 : 0.4\n",
        "- 50 epochs, batch size 32, lr 0.0005: 0.4\n",
        "- 50 epochs, batch size 16, lr 0.001: 0.38\n",
        "- VGG16_bn, 50 epochs, batch size 32, lr: 0.001: 0.43\n",
        "- VGG16_bn, 50 epochs, batch size 32, lr: 0.004: 0.39\n",
        "\n",
        "avg. accuracies (step size 10, gamma 0.05)\n",
        "- VGG16_bn, 50 epochs, batch size 32, lr: 0.001: 0.56\n",
        "- VGG16_bn, 100 epochs, batch size 32, lr: 0.001, step size: 15, gamma: 0.05: 0.49\n",
        "- VGG16_bn, 50 epochs, batch size 32, lr: 0.001, no LR scheduler: 0.78\n",
        "- VGG16_bn, 50 epochs, batch size 40, lr: 0.001, no LR scheduler [note: overfitting after epoch 26]: 0.807\n",
        "- VGG16_bn, 50 epochs, batch size 40, lr: 0.001, step size: 25, gamma: 0.05: 0.67\n",
        "- VGG16_bn, 50 epochs, batch size 40, lr: 0.001, step size: 25, gamma: 0.90: 0.807\n",
        "- VGG16_bn, 50 epochs, batch size 40, lr: 0.001, step size: 25, gamma: 0.95: 0.807\n",
        "- VGG16_bn, 100 epochs, batch size 40: lr: 0.002, step size: 25, gamma: 0.95: 0.791\n",
        "- VGG16_bn, 50 epochs, batch size 40: lr: 0.002, step size: 25, gamma: 0.85: 0.71\n",
        "- **VGG16_bn, 100 epochs, batch size 40, lr: 0.001, step size: 25, gamma: 0.95: 0.848**\n",
        "- VGG16_bn, 50 epochs, batch size 40, lr: 0.001, step size: 25, gamma: 0.85: 0.76\n"
      ],
      "metadata": {
        "id": "p5GYTWjSD_6y"
      }
    }
  ]
}