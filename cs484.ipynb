{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwWPSYKD0GoQ",
        "outputId": "b19e9eb4-c5ae-452b-99c1-a1e2a0311cc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cs484'...\n",
            "remote: Enumerating objects: 298, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 298 (delta 7), reused 14 (delta 5), pack-reused 282\u001b[K\n",
            "Receiving objects: 100% (298/298), 83.49 MiB | 16.73 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf cs484 && git clone https://github.com/berkan-sahin/cs484.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -U torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Nvh0OLr9c2j",
        "outputId": "db633599-cfab-4257-e3d8-7e399abe8c06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
        "import time\n",
        "import copy\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZmY-amFpSQm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HockeyDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data_dir, transformer) -> None:\n",
        "        self.data_dir = data_dir\n",
        "        self.transformer = transformer\n",
        "\n",
        "    def __len__(self):\n",
        "        return 192\n",
        "\n",
        "    def __getitem__(self, index) -> Tuple[any, any]:\n",
        "        class_idx = index / 64\n",
        "        if (class_idx < 1):\n",
        "            class_name = 'freehit'\n",
        "        elif (class_idx < 2):\n",
        "            class_name = 'goal'\n",
        "        elif (class_idx < 3):\n",
        "            class_name = 'penaltycorner'\n",
        "        else:\n",
        "            class_name = 'penaltyshot'  # should never happen\n",
        "\n",
        "        img_name = os.path.join(self.data_dir, class_name,\n",
        "                                f'{(index % 64) + 1}.jpg')\n",
        "        image = read_image(img_name).to(torch.float32)\n",
        "        image = self.transformer(image)\n",
        "        return image, class_idx\n",
        "\n",
        "\n",
        "preprocess = transforms.Compose([\n",
        "    # transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    transforms.Resize(256, antialias=True),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    # transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "rmyKvWKX7ive"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- modified the learning rate (from 0.0001 to 0.001)\n",
        "- using pytorch's pretrained weights\n",
        "- freezing the feature detection layers\n",
        "- bugfixes\n",
        "- batch size incremented to 32 from 4"
      ],
      "metadata": {
        "id": "LJ1LgTGXRGmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if True:    \n",
        "    fold = 6\n",
        "    epochs = 100\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device: \", device)\n",
        "    #vgg16 = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
        "    vgg16 = models.vgg16_bn(weights=models.VGG16_BN_Weights.IMAGENET1K_V1)\n",
        "    # vgg16.load_state_dict(torch.load('vgg16.pth'))\n",
        "    # reset the last layer\n",
        "    # Freeze training for all layers\n",
        "    for param in vgg16.features.parameters():\n",
        "      param.require_grad = False\n",
        "\n",
        "    in_features = vgg16.classifier[-1].in_features\n",
        "    classifier = list(vgg16.classifier.children())[:-1]\n",
        "    classifier.extend([nn.Linear(in_features, 3)])\n",
        "    vgg16.classifier = nn.Sequential(*classifier)\n",
        "    print(vgg16.classifier)\n",
        "    vgg16 = vgg16.to(device)\n",
        "    if torch.cuda.is_available():\n",
        "        vgg16.cuda()\n",
        "    dataset = HockeyDataset(\n",
        "        'cs484/dataset', models.VGG16_Weights.IMAGENET1K_V1.transforms(antialias=True))\n",
        "    # kfold = KFold(n_splits=fold, shuffle=True)\n",
        "    kfold = StratifiedKFold(n_splits=fold, shuffle=True, random_state=3)\n",
        "\n",
        " #   train_size = int(0.8 * len(dataset))\n",
        " #   test_size = len(dataset) - train_size\n",
        " #   train, test = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "    begin = time.time()\n",
        "    initial_weight = copy.deepcopy(vgg16.state_dict())\n",
        "    accuracy = []\n",
        "    best_epochs = []\n",
        "    for (fold, (train, test)) in enumerate(kfold.split(dataset, np.full(64, 0).tolist() + np.full(64, 1).tolist() + np.full(64, 2).tolist())):\n",
        "        print(\"Train: \", train, \"Validation: \", test)\n",
        "        trainloader = DataLoader(dataset, batch_size=40, sampler=train, num_workers=2)\n",
        "        valloader = DataLoader(dataset, batch_size=40, sampler=test, num_workers=2)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(vgg16.parameters(), lr=0.001)\n",
        "        #optimizer_ft = optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)\n",
        "        scheduler = optim.lr_scheduler.StepLR(\n",
        "               optimizer, step_size=25, gamma=0.85)\n",
        "\n",
        "        vgg16.load_state_dict(initial_weight)\n",
        "        best_weight = copy.deepcopy(initial_weight)\n",
        "        best_acc = 0.0\n",
        "        best_epoch = 0\n",
        "        for epoch in range(epochs):\n",
        "            # Training phase\n",
        "            vgg16.train()\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            for inputs, labels in trainloader:\n",
        "                labels = labels.type(torch.LongTensor)\n",
        "                #inputs = inputs.to(device)\n",
        "                #labels = labels.to(device)\n",
        "\n",
        "                if torch.cuda.is_available():\n",
        "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
        "                else:\n",
        "                    inputs, labels = Variable(inputs), Variable(labels)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = vgg16(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                #print(type(labels))\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                scheduler.step()\n",
        "\n",
        "                del inputs, outputs, labels, preds\n",
        "\n",
        "            epoch_loss = running_loss / len(train)\n",
        "            epoch_acc = running_corrects.double() / len(train)\n",
        "            print('Epoch: {} train Loss: {:.4f} Acc: {:.4f}'.format(epoch, epoch_loss, epoch_acc))\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            vgg16.eval()\n",
        "            with torch.no_grad():\n",
        "                for images, labels in valloader:\n",
        "                    labels = labels.type(torch.LongTensor)\n",
        "                    optimizer.zero_grad()\n",
        "                    #images = images.to(device)\n",
        "                    #labels = labels.to(device)\n",
        "\n",
        "                    if torch.cuda.is_available():\n",
        "                      images, labels = Variable(images.cuda()), Variable(labels.cuda())\n",
        "                    else:\n",
        "                      images, labels = Variable(images), Variable(labels)\n",
        "                    outputs = vgg16(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    running_loss += loss.item() * images.size(0)\n",
        "                    running_corrects += torch.sum(predicted == labels.data)\n",
        "            \n",
        "            epoch_loss = running_loss / len(test)\n",
        "            epoch_acc = running_corrects.double() / len(test)\n",
        "            print('Epoch: {} eval Loss: {:.4f} Acc: {:.4f}'.format(epoch, epoch_loss, epoch_acc))\n",
        "\n",
        "            if epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_weight = copy.deepcopy(vgg16.state_dict())\n",
        "                best_epoch = epoch\n",
        "        \n",
        "        accuracy.append(best_acc)\n",
        "        best_epochs.append(best_epoch)\n",
        "        print(f\"Fold {fold} accuracy: {best_acc} achieved in epoch {best_epoch}\")\n",
        "        #torch.save(best_weight, f\"vgg16_fold{fold}.pth\")\n",
        "\n",
        "\n",
        "    time_elapsed = time.time() - begin\n",
        "    print(f\"Finished Training, took {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s\")\n",
        "    print(f\"Average accuracy: {sum(accuracy) / len(accuracy)}\")\n",
        "    print(f\"Average epoch: {sum(best_epochs) / len(best_epochs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQz9chVi7p6O",
        "outputId": "400102ce-5f5f-4844-9c3f-1d879e9f1c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device:  cuda:0\n",
            "Sequential(\n",
            "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): Dropout(p=0.5, inplace=False)\n",
            "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): Dropout(p=0.5, inplace=False)\n",
            "  (6): Linear(in_features=4096, out_features=3, bias=True)\n",
            ")\n",
            "Train:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  15  17  18  19  20\n",
            "  21  22  23  24  25  26  27  29  30  31  32  33  35  37  39  40  41  42\n",
            "  43  44  45  46  47  48  49  50  51  52  53  55  56  59  61  62  63  64\n",
            "  65  67  69  71  72  74  75  76  77  78  79  80  81  84  86  87  88  89\n",
            "  90  92  93  94  95  96  97  98  99 101 102 103 104 105 107 108 109 110\n",
            " 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 131\n",
            " 132 133 135 136 137 138 139 140 141 143 144 145 146 147 148 149 150 152\n",
            " 153 154 155 156 157 159 160 161 162 163 164 165 166 167 169 170 171 172\n",
            " 173 174 175 176 178 180 181 182 183 184 185 186 188 189 190 191] Validation:  [  0  14  16  28  34  36  38  54  57  58  60  66  68  70  73  82  83  85\n",
            "  91 100 106 111 129 130 134 142 151 158 168 177 179 187]\n",
            "Epoch: 0 train Loss: 5.9717 Acc: 0.1188\n",
            "Epoch: 0 eval Loss: 1.0950 Acc: 0.3438\n",
            "Epoch: 1 train Loss: 1.4132 Acc: 0.1500\n",
            "Epoch: 1 eval Loss: 1.1015 Acc: 0.3125\n",
            "Epoch: 2 train Loss: 1.0530 Acc: 0.3938\n",
            "Epoch: 2 eval Loss: 1.0176 Acc: 0.5312\n",
            "Epoch: 3 train Loss: 0.9184 Acc: 0.6375\n",
            "Epoch: 3 eval Loss: 0.8854 Acc: 0.6250\n",
            "Epoch: 4 train Loss: 0.7709 Acc: 0.6500\n",
            "Epoch: 4 eval Loss: 0.7959 Acc: 0.6250\n",
            "Epoch: 5 train Loss: 0.5862 Acc: 0.7313\n",
            "Epoch: 5 eval Loss: 0.6991 Acc: 0.7500\n",
            "Epoch: 6 train Loss: 0.3901 Acc: 0.8375\n",
            "Epoch: 6 eval Loss: 0.5858 Acc: 0.8125\n",
            "Epoch: 7 train Loss: 0.2790 Acc: 0.9062\n",
            "Epoch: 7 eval Loss: 0.4621 Acc: 0.8438\n",
            "Epoch: 8 train Loss: 0.1428 Acc: 0.9500\n",
            "Epoch: 8 eval Loss: 0.7155 Acc: 0.7188\n",
            "Epoch: 9 train Loss: 0.1827 Acc: 0.9125\n",
            "Epoch: 9 eval Loss: 0.7759 Acc: 0.8125\n",
            "Epoch: 10 train Loss: 0.2624 Acc: 0.9250\n",
            "Epoch: 10 eval Loss: 1.4499 Acc: 0.6250\n",
            "Epoch: 11 train Loss: 0.2005 Acc: 0.9313\n",
            "Epoch: 11 eval Loss: 2.4894 Acc: 0.5625\n",
            "Epoch: 12 train Loss: 0.1741 Acc: 0.9625\n",
            "Epoch: 12 eval Loss: 1.2111 Acc: 0.7812\n",
            "Epoch: 13 train Loss: 0.3867 Acc: 0.8875\n",
            "Epoch: 13 eval Loss: 0.6023 Acc: 0.8438\n",
            "Epoch: 14 train Loss: 0.0788 Acc: 0.9875\n",
            "Epoch: 14 eval Loss: 1.1547 Acc: 0.7500\n",
            "Epoch: 15 train Loss: 0.1377 Acc: 0.9625\n",
            "Epoch: 15 eval Loss: 0.9285 Acc: 0.7812\n",
            "Epoch: 16 train Loss: 0.0669 Acc: 0.9875\n",
            "Epoch: 16 eval Loss: 0.8380 Acc: 0.7812\n",
            "Epoch: 17 train Loss: 0.1031 Acc: 0.9688\n",
            "Epoch: 17 eval Loss: 0.9748 Acc: 0.7500\n",
            "Epoch: 18 train Loss: 0.3262 Acc: 0.9438\n",
            "Epoch: 18 eval Loss: 1.5404 Acc: 0.6562\n",
            "Epoch: 19 train Loss: 0.0779 Acc: 0.9813\n",
            "Epoch: 19 eval Loss: 1.8047 Acc: 0.7188\n",
            "Epoch: 20 train Loss: 0.0204 Acc: 1.0000\n",
            "Epoch: 20 eval Loss: 1.2847 Acc: 0.7812\n",
            "Epoch: 21 train Loss: 0.0192 Acc: 0.9938\n",
            "Epoch: 21 eval Loss: 1.1823 Acc: 0.8125\n",
            "Epoch: 22 train Loss: 0.0155 Acc: 0.9938\n",
            "Epoch: 22 eval Loss: 1.1888 Acc: 0.8125\n",
            "Epoch: 23 train Loss: 0.0154 Acc: 0.9938\n",
            "Epoch: 23 eval Loss: 1.1537 Acc: 0.8125\n",
            "Epoch: 24 train Loss: 0.0094 Acc: 0.9938\n",
            "Epoch: 24 eval Loss: 1.0487 Acc: 0.8438\n",
            "Epoch: 25 train Loss: 0.0072 Acc: 1.0000\n",
            "Epoch: 25 eval Loss: 0.9652 Acc: 0.8438\n",
            "Epoch: 26 train Loss: 0.0069 Acc: 1.0000\n",
            "Epoch: 26 eval Loss: 0.9076 Acc: 0.8438\n",
            "Epoch: 27 train Loss: 0.0062 Acc: 1.0000\n",
            "Epoch: 27 eval Loss: 0.8664 Acc: 0.8438\n",
            "Epoch: 28 train Loss: 0.0033 Acc: 1.0000\n",
            "Epoch: 28 eval Loss: 0.8368 Acc: 0.8438\n",
            "Epoch: 29 train Loss: 0.0031 Acc: 1.0000\n",
            "Epoch: 29 eval Loss: 0.8196 Acc: 0.8438\n",
            "Epoch: 30 train Loss: 0.0014 Acc: 1.0000\n",
            "Epoch: 30 eval Loss: 0.8131 Acc: 0.8438\n",
            "Epoch: 31 train Loss: 0.0010 Acc: 1.0000\n",
            "Epoch: 31 eval Loss: 0.8179 Acc: 0.8438\n",
            "Epoch: 32 train Loss: 0.0012 Acc: 1.0000\n",
            "Epoch: 32 eval Loss: 0.8263 Acc: 0.8438\n",
            "Epoch: 33 train Loss: 0.0005 Acc: 1.0000\n",
            "Epoch: 33 eval Loss: 0.8364 Acc: 0.8438\n",
            "Epoch: 34 train Loss: 0.0005 Acc: 1.0000\n",
            "Epoch: 34 eval Loss: 0.8492 Acc: 0.8438\n",
            "Epoch: 35 train Loss: 0.0006 Acc: 1.0000\n",
            "Epoch: 35 eval Loss: 0.8627 Acc: 0.8438\n",
            "Epoch: 36 train Loss: 0.0005 Acc: 1.0000\n",
            "Epoch: 36 eval Loss: 0.8754 Acc: 0.8438\n",
            "Epoch: 37 train Loss: 0.0005 Acc: 1.0000\n",
            "Epoch: 37 eval Loss: 0.8866 Acc: 0.8438\n",
            "Epoch: 38 train Loss: 0.0006 Acc: 1.0000\n",
            "Epoch: 38 eval Loss: 0.8955 Acc: 0.8438\n",
            "Epoch: 39 train Loss: 0.0006 Acc: 1.0000\n",
            "Epoch: 39 eval Loss: 0.9018 Acc: 0.8438\n",
            "Epoch: 40 train Loss: 0.0004 Acc: 1.0000\n",
            "Epoch: 40 eval Loss: 0.9071 Acc: 0.8438\n",
            "Epoch: 41 train Loss: 0.0005 Acc: 1.0000\n",
            "Epoch: 41 eval Loss: 0.9131 Acc: 0.8438\n",
            "Epoch: 42 train Loss: 0.0004 Acc: 1.0000\n",
            "Epoch: 42 eval Loss: 0.9203 Acc: 0.8438\n",
            "Epoch: 43 train Loss: 0.0004 Acc: 1.0000\n",
            "Epoch: 43 eval Loss: 0.9295 Acc: 0.8438\n",
            "Epoch: 44 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 44 eval Loss: 0.9362 Acc: 0.8438\n",
            "Epoch: 45 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 45 eval Loss: 0.9419 Acc: 0.8438\n",
            "Epoch: 46 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 46 eval Loss: 0.9475 Acc: 0.8438\n",
            "Epoch: 47 train Loss: 0.0004 Acc: 1.0000\n",
            "Epoch: 47 eval Loss: 0.9531 Acc: 0.8438\n",
            "Epoch: 48 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 48 eval Loss: 0.9584 Acc: 0.8438\n",
            "Epoch: 49 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 49 eval Loss: 0.9631 Acc: 0.8438\n",
            "Epoch: 50 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 50 eval Loss: 0.9667 Acc: 0.8438\n",
            "Epoch: 51 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 51 eval Loss: 0.9698 Acc: 0.8438\n",
            "Epoch: 52 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 52 eval Loss: 0.9727 Acc: 0.8438\n",
            "Epoch: 53 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 53 eval Loss: 0.9758 Acc: 0.8438\n",
            "Epoch: 54 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 54 eval Loss: 0.9787 Acc: 0.8438\n",
            "Epoch: 55 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 55 eval Loss: 0.9816 Acc: 0.8438\n",
            "Epoch: 56 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 56 eval Loss: 0.9842 Acc: 0.8438\n",
            "Epoch: 57 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 57 eval Loss: 0.9860 Acc: 0.8438\n",
            "Epoch: 58 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 58 eval Loss: 0.9874 Acc: 0.8438\n",
            "Epoch: 59 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 59 eval Loss: 0.9892 Acc: 0.8438\n",
            "Epoch: 60 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 60 eval Loss: 0.9916 Acc: 0.8438\n",
            "Epoch: 61 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 61 eval Loss: 0.9945 Acc: 0.8438\n",
            "Epoch: 62 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 62 eval Loss: 0.9966 Acc: 0.8438\n",
            "Epoch: 63 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 63 eval Loss: 0.9988 Acc: 0.8438\n",
            "Epoch: 64 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 64 eval Loss: 1.0011 Acc: 0.8438\n",
            "Epoch: 65 train Loss: 0.0125 Acc: 0.9938\n",
            "Epoch: 65 eval Loss: 0.7174 Acc: 0.9062\n",
            "Epoch: 66 train Loss: 0.0026 Acc: 1.0000\n",
            "Epoch: 66 eval Loss: 0.8800 Acc: 0.8125\n",
            "Epoch: 67 train Loss: 0.0175 Acc: 0.9875\n",
            "Epoch: 67 eval Loss: 1.1653 Acc: 0.7812\n",
            "Epoch: 68 train Loss: 0.0199 Acc: 0.9938\n",
            "Epoch: 68 eval Loss: 1.3792 Acc: 0.7812\n",
            "Epoch: 69 train Loss: 0.0047 Acc: 1.0000\n",
            "Epoch: 69 eval Loss: 0.8243 Acc: 0.8125\n",
            "Epoch: 70 train Loss: 0.0018 Acc: 1.0000\n",
            "Epoch: 70 eval Loss: 0.6930 Acc: 0.8438\n",
            "Epoch: 71 train Loss: 0.0007 Acc: 1.0000\n",
            "Epoch: 71 eval Loss: 0.6644 Acc: 0.8750\n",
            "Epoch: 72 train Loss: 0.0012 Acc: 1.0000\n",
            "Epoch: 72 eval Loss: 0.6662 Acc: 0.8750\n",
            "Epoch: 73 train Loss: 0.0012 Acc: 1.0000\n",
            "Epoch: 73 eval Loss: 0.6792 Acc: 0.8750\n",
            "Epoch: 74 train Loss: 0.0008 Acc: 1.0000\n",
            "Epoch: 74 eval Loss: 0.6984 Acc: 0.8438\n",
            "Epoch: 75 train Loss: 0.0006 Acc: 1.0000\n",
            "Epoch: 75 eval Loss: 0.7202 Acc: 0.8438\n",
            "Epoch: 76 train Loss: 0.0005 Acc: 1.0000\n",
            "Epoch: 76 eval Loss: 0.7402 Acc: 0.8438\n",
            "Epoch: 77 train Loss: 0.0005 Acc: 1.0000\n",
            "Epoch: 77 eval Loss: 0.7550 Acc: 0.8125\n",
            "Epoch: 78 train Loss: 0.0006 Acc: 1.0000\n",
            "Epoch: 78 eval Loss: 0.7652 Acc: 0.8125\n",
            "Epoch: 79 train Loss: 0.0006 Acc: 1.0000\n",
            "Epoch: 79 eval Loss: 0.7730 Acc: 0.8125\n",
            "Epoch: 80 train Loss: 0.0006 Acc: 1.0000\n",
            "Epoch: 80 eval Loss: 0.7790 Acc: 0.8125\n",
            "Epoch: 81 train Loss: 0.0005 Acc: 1.0000\n",
            "Epoch: 81 eval Loss: 0.7832 Acc: 0.8125\n",
            "Epoch: 82 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 82 eval Loss: 0.7866 Acc: 0.8125\n",
            "Epoch: 83 train Loss: 0.0004 Acc: 1.0000\n",
            "Epoch: 83 eval Loss: 0.7896 Acc: 0.8125\n",
            "Epoch: 84 train Loss: 0.0004 Acc: 1.0000\n",
            "Epoch: 84 eval Loss: 0.7924 Acc: 0.8125\n",
            "Epoch: 85 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 85 eval Loss: 0.7955 Acc: 0.8125\n",
            "Epoch: 86 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 86 eval Loss: 0.7982 Acc: 0.8125\n",
            "Epoch: 87 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 87 eval Loss: 0.8004 Acc: 0.8125\n",
            "Epoch: 88 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 88 eval Loss: 0.8023 Acc: 0.8125\n",
            "Epoch: 89 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 89 eval Loss: 0.8041 Acc: 0.8125\n",
            "Epoch: 90 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 90 eval Loss: 0.8058 Acc: 0.8125\n",
            "Epoch: 91 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 91 eval Loss: 0.8073 Acc: 0.8125\n",
            "Epoch: 92 train Loss: 0.0006 Acc: 1.0000\n",
            "Epoch: 92 eval Loss: 0.8090 Acc: 0.8125\n",
            "Epoch: 93 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 93 eval Loss: 0.8106 Acc: 0.8125\n",
            "Epoch: 94 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 94 eval Loss: 0.8121 Acc: 0.8125\n",
            "Epoch: 95 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 95 eval Loss: 0.8133 Acc: 0.8125\n",
            "Epoch: 96 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 96 eval Loss: 0.8143 Acc: 0.8125\n",
            "Epoch: 97 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 97 eval Loss: 0.8152 Acc: 0.8125\n",
            "Epoch: 98 train Loss: 0.0004 Acc: 1.0000\n",
            "Epoch: 98 eval Loss: 0.8162 Acc: 0.8125\n",
            "Epoch: 99 train Loss: 0.0004 Acc: 1.0000\n",
            "Epoch: 99 eval Loss: 0.8174 Acc: 0.8125\n",
            "Fold 0 accuracy: 0.90625 achieved in epoch 65\n",
            "Train:  [  0   1   2   3   4   5   6   7   8  10  12  13  14  15  16  18  19  20\n",
            "  21  22  25  27  28  29  30  31  32  33  34  35  36  37  38  39  40  42\n",
            "  44  45  46  48  49  50  51  52  53  54  57  58  59  60  61  62  63  64\n",
            "  66  67  68  69  70  71  73  74  75  76  77  79  80  81  82  83  84  85\n",
            "  86  87  89  90  91  93  94  95  97  98  99 100 101 102 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 117 118 121 122 123 124 126 127 128 129\n",
            " 130 131 132 134 135 136 137 138 139 140 142 143 144 145 146 149 150 151\n",
            " 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 170\n",
            " 171 173 174 175 176 177 178 179 180 184 185 186 187 188 189 190] Validation:  [  9  11  17  23  24  26  41  43  47  55  56  65  72  78  88  92  96 103\n",
            " 116 119 120 125 133 141 147 148 169 172 181 182 183 191]\n",
            "Epoch: 0 train Loss: 7.0606 Acc: 0.1438\n",
            "Epoch: 0 eval Loss: 3.7868 Acc: 0.3438\n",
            "Epoch: 1 train Loss: 1.2913 Acc: 0.1750\n",
            "Epoch: 1 eval Loss: 0.9682 Acc: 0.5312\n",
            "Epoch: 2 train Loss: 1.0366 Acc: 0.4625\n",
            "Epoch: 2 eval Loss: 1.7348 Acc: 0.3750\n",
            "Epoch: 3 train Loss: 0.9000 Acc: 0.5875\n",
            "Epoch: 3 eval Loss: 2.3894 Acc: 0.5625\n",
            "Epoch: 4 train Loss: 0.7294 Acc: 0.6438\n",
            "Epoch: 4 eval Loss: 2.2490 Acc: 0.6562\n",
            "Epoch: 5 train Loss: 0.7454 Acc: 0.6438\n",
            "Epoch: 5 eval Loss: 1.2473 Acc: 0.6562\n",
            "Epoch: 6 train Loss: 0.4862 Acc: 0.7500\n",
            "Epoch: 6 eval Loss: 0.6238 Acc: 0.6875\n",
            "Epoch: 7 train Loss: 0.4589 Acc: 0.8000\n",
            "Epoch: 7 eval Loss: 0.6136 Acc: 0.7500\n",
            "Epoch: 8 train Loss: 0.3102 Acc: 0.8375\n",
            "Epoch: 8 eval Loss: 0.7677 Acc: 0.7500\n",
            "Epoch: 9 train Loss: 0.1984 Acc: 0.9313\n",
            "Epoch: 9 eval Loss: 2.2885 Acc: 0.6562\n",
            "Epoch: 10 train Loss: 0.1808 Acc: 0.9125\n",
            "Epoch: 10 eval Loss: 0.6529 Acc: 0.8438\n",
            "Epoch: 11 train Loss: 0.1583 Acc: 0.9563\n",
            "Epoch: 11 eval Loss: 0.7574 Acc: 0.7812\n",
            "Epoch: 12 train Loss: 0.1722 Acc: 0.9438\n",
            "Epoch: 12 eval Loss: 1.0014 Acc: 0.6562\n",
            "Epoch: 13 train Loss: 0.2181 Acc: 0.9000\n",
            "Epoch: 13 eval Loss: 32.0552 Acc: 0.4375\n",
            "Epoch: 14 train Loss: 0.4227 Acc: 0.8438\n",
            "Epoch: 14 eval Loss: 2.0695 Acc: 0.6875\n",
            "Epoch: 15 train Loss: 0.2574 Acc: 0.8938\n",
            "Epoch: 15 eval Loss: 0.6216 Acc: 0.7812\n",
            "Epoch: 16 train Loss: 0.1691 Acc: 0.9438\n",
            "Epoch: 16 eval Loss: 1.1347 Acc: 0.5938\n",
            "Epoch: 17 train Loss: 0.1360 Acc: 0.9563\n",
            "Epoch: 17 eval Loss: 1.5238 Acc: 0.5938\n",
            "Epoch: 18 train Loss: 0.0811 Acc: 0.9875\n",
            "Epoch: 18 eval Loss: 1.7939 Acc: 0.5625\n",
            "Epoch: 19 train Loss: 0.0453 Acc: 0.9813\n",
            "Epoch: 19 eval Loss: 1.7633 Acc: 0.5938\n",
            "Epoch: 20 train Loss: 0.0291 Acc: 0.9938\n",
            "Epoch: 20 eval Loss: 1.3859 Acc: 0.6562\n",
            "Epoch: 21 train Loss: 0.0130 Acc: 0.9938\n",
            "Epoch: 21 eval Loss: 1.2283 Acc: 0.6562\n",
            "Epoch: 22 train Loss: 0.0111 Acc: 0.9938\n",
            "Epoch: 22 eval Loss: 1.1954 Acc: 0.6875\n",
            "Epoch: 23 train Loss: 0.0099 Acc: 0.9938\n",
            "Epoch: 23 eval Loss: 1.2078 Acc: 0.6875\n",
            "Epoch: 24 train Loss: 0.0101 Acc: 0.9938\n",
            "Epoch: 24 eval Loss: 1.2812 Acc: 0.6875\n",
            "Epoch: 25 train Loss: 0.0049 Acc: 1.0000\n",
            "Epoch: 25 eval Loss: 1.2591 Acc: 0.6562\n",
            "Epoch: 26 train Loss: 0.0014 Acc: 1.0000\n",
            "Epoch: 26 eval Loss: 1.2973 Acc: 0.6562\n",
            "Epoch: 27 train Loss: 0.0012 Acc: 1.0000\n",
            "Epoch: 27 eval Loss: 1.3760 Acc: 0.6250\n",
            "Epoch: 28 train Loss: 0.0008 Acc: 1.0000\n",
            "Epoch: 28 eval Loss: 1.4305 Acc: 0.6250\n",
            "Epoch: 29 train Loss: 0.0006 Acc: 1.0000\n",
            "Epoch: 29 eval Loss: 1.4593 Acc: 0.6250\n",
            "Epoch: 30 train Loss: 0.0004 Acc: 1.0000\n",
            "Epoch: 30 eval Loss: 1.4692 Acc: 0.6250\n",
            "Epoch: 31 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 31 eval Loss: 1.4731 Acc: 0.6250\n",
            "Epoch: 32 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 32 eval Loss: 1.4739 Acc: 0.6250\n",
            "Epoch: 33 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 33 eval Loss: 1.4783 Acc: 0.6250\n",
            "Epoch: 34 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 34 eval Loss: 1.4838 Acc: 0.6250\n",
            "Epoch: 35 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 35 eval Loss: 1.4893 Acc: 0.6562\n",
            "Epoch: 36 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 36 eval Loss: 1.4947 Acc: 0.6562\n",
            "Epoch: 37 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 37 eval Loss: 1.5001 Acc: 0.6875\n",
            "Epoch: 38 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 38 eval Loss: 1.5038 Acc: 0.6875\n",
            "Epoch: 39 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 39 eval Loss: 1.5090 Acc: 0.6875\n",
            "Epoch: 40 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 40 eval Loss: 1.5121 Acc: 0.6875\n",
            "Epoch: 41 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 41 eval Loss: 1.5116 Acc: 0.6875\n",
            "Epoch: 42 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 42 eval Loss: 1.5134 Acc: 0.6875\n",
            "Epoch: 43 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 43 eval Loss: 1.5139 Acc: 0.6875\n",
            "Epoch: 44 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 44 eval Loss: 1.5149 Acc: 0.6875\n",
            "Epoch: 45 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 45 eval Loss: 1.5163 Acc: 0.6875\n",
            "Epoch: 46 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 46 eval Loss: 1.5183 Acc: 0.6875\n",
            "Epoch: 47 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 47 eval Loss: 1.5198 Acc: 0.6875\n",
            "Epoch: 48 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 48 eval Loss: 1.5217 Acc: 0.6875\n",
            "Epoch: 49 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 49 eval Loss: 1.5234 Acc: 0.6875\n",
            "Epoch: 50 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 50 eval Loss: 1.5244 Acc: 0.6875\n",
            "Epoch: 51 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 51 eval Loss: 1.5246 Acc: 0.6875\n",
            "Epoch: 52 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 52 eval Loss: 1.5247 Acc: 0.6875\n",
            "Epoch: 53 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 53 eval Loss: 1.5258 Acc: 0.6875\n",
            "Epoch: 54 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 54 eval Loss: 1.5267 Acc: 0.6875\n",
            "Epoch: 55 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 55 eval Loss: 1.5279 Acc: 0.6875\n",
            "Epoch: 56 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 56 eval Loss: 1.5281 Acc: 0.6875\n",
            "Epoch: 57 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 57 eval Loss: 1.5289 Acc: 0.6875\n",
            "Epoch: 58 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 58 eval Loss: 1.5289 Acc: 0.6875\n",
            "Epoch: 59 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 59 eval Loss: 1.5286 Acc: 0.6875\n",
            "Epoch: 60 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 60 eval Loss: 1.5288 Acc: 0.6875\n",
            "Epoch: 61 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 61 eval Loss: 1.5288 Acc: 0.6875\n",
            "Epoch: 62 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 62 eval Loss: 1.5266 Acc: 0.6875\n",
            "Epoch: 63 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 63 eval Loss: 1.5222 Acc: 0.6875\n",
            "Epoch: 64 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 64 eval Loss: 1.5195 Acc: 0.6875\n",
            "Epoch: 65 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 65 eval Loss: 1.5181 Acc: 0.6875\n",
            "Epoch: 66 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 66 eval Loss: 1.5173 Acc: 0.6875\n",
            "Epoch: 67 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 67 eval Loss: 1.5164 Acc: 0.6875\n",
            "Epoch: 68 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 68 eval Loss: 1.5162 Acc: 0.6875\n",
            "Epoch: 69 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 69 eval Loss: 1.5108 Acc: 0.6875\n",
            "Epoch: 70 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 70 eval Loss: 1.5063 Acc: 0.6875\n",
            "Epoch: 71 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 71 eval Loss: 1.5039 Acc: 0.6875\n",
            "Epoch: 72 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 72 eval Loss: 1.5025 Acc: 0.6875\n",
            "Epoch: 73 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 73 eval Loss: 1.5014 Acc: 0.6875\n",
            "Epoch: 74 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 74 eval Loss: 1.5002 Acc: 0.6875\n",
            "Epoch: 75 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 75 eval Loss: 1.4989 Acc: 0.6875\n",
            "Epoch: 76 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 76 eval Loss: 1.4983 Acc: 0.6875\n",
            "Epoch: 77 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 77 eval Loss: 1.4983 Acc: 0.6875\n",
            "Epoch: 78 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 78 eval Loss: 1.4991 Acc: 0.6875\n",
            "Epoch: 79 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 79 eval Loss: 1.5003 Acc: 0.6875\n",
            "Epoch: 80 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 80 eval Loss: 1.5003 Acc: 0.6875\n",
            "Epoch: 81 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 81 eval Loss: 1.5010 Acc: 0.6875\n",
            "Epoch: 82 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 82 eval Loss: 1.5013 Acc: 0.6875\n",
            "Epoch: 83 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 83 eval Loss: 1.5016 Acc: 0.6875\n",
            "Epoch: 84 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 84 eval Loss: 1.5019 Acc: 0.6875\n",
            "Epoch: 85 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 85 eval Loss: 1.5025 Acc: 0.6875\n",
            "Epoch: 86 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 86 eval Loss: 1.5032 Acc: 0.6875\n",
            "Epoch: 87 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 87 eval Loss: 1.5041 Acc: 0.6875\n",
            "Epoch: 88 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 88 eval Loss: 1.5052 Acc: 0.6875\n",
            "Epoch: 89 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 89 eval Loss: 1.5060 Acc: 0.6875\n",
            "Epoch: 90 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 90 eval Loss: 1.5057 Acc: 0.6875\n",
            "Epoch: 91 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 91 eval Loss: 1.5061 Acc: 0.6875\n",
            "Epoch: 92 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 92 eval Loss: 1.5066 Acc: 0.6875\n",
            "Epoch: 93 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 93 eval Loss: 1.5076 Acc: 0.6875\n",
            "Epoch: 94 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 94 eval Loss: 1.5083 Acc: 0.6875\n",
            "Epoch: 95 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 95 eval Loss: 1.5088 Acc: 0.6875\n",
            "Epoch: 96 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 96 eval Loss: 1.5095 Acc: 0.6875\n",
            "Epoch: 97 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 97 eval Loss: 1.5102 Acc: 0.6875\n",
            "Epoch: 98 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 98 eval Loss: 1.5109 Acc: 0.6875\n",
            "Epoch: 99 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 99 eval Loss: 1.5113 Acc: 0.6875\n",
            "Fold 1 accuracy: 0.84375 achieved in epoch 10\n",
            "Train:  [  0   1   2   3   4   7   9  11  12  13  14  15  16  17  18  19  20  21\n",
            "  22  23  24  25  26  28  30  31  32  33  34  35  36  37  38  40  41  43\n",
            "  44  46  47  49  50  51  52  53  54  55  56  57  58  59  60  61  63  64\n",
            "  65  66  67  68  70  71  72  73  75  76  77  78  80  81  82  83  84  85\n",
            "  86  87  88  89  90  91  92  93  94  95  96  97  99 100 101 103 104 105\n",
            " 106 107 109 111 112 113 115 116 118 119 120 121 122 123 124 125 127 129\n",
            " 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147\n",
            " 148 149 151 152 154 155 158 159 160 162 163 164 165 166 168 169 170 171\n",
            " 172 173 174 175 176 177 179 180 181 182 183 185 187 188 189 191] Validation:  [  5   6   8  10  27  29  39  42  45  48  62  69  74  79  98 102 108 110\n",
            " 114 117 126 128 150 153 156 157 161 167 178 184 186 190]\n",
            "Epoch: 0 train Loss: 7.1953 Acc: 0.1375\n",
            "Epoch: 0 eval Loss: 1.1037 Acc: 0.3125\n",
            "Epoch: 1 train Loss: 1.5524 Acc: 0.2063\n",
            "Epoch: 1 eval Loss: 1.0042 Acc: 0.5312\n",
            "Epoch: 2 train Loss: 0.9564 Acc: 0.5813\n",
            "Epoch: 2 eval Loss: 1.4640 Acc: 0.3438\n",
            "Epoch: 3 train Loss: 0.9503 Acc: 0.6375\n",
            "Epoch: 3 eval Loss: 1.9272 Acc: 0.4062\n",
            "Epoch: 4 train Loss: 0.9501 Acc: 0.5875\n",
            "Epoch: 4 eval Loss: 1.5371 Acc: 0.5312\n",
            "Epoch: 5 train Loss: 0.9008 Acc: 0.6313\n",
            "Epoch: 5 eval Loss: 1.1919 Acc: 0.5938\n",
            "Epoch: 6 train Loss: 0.8277 Acc: 0.7000\n",
            "Epoch: 6 eval Loss: 0.9989 Acc: 0.5938\n",
            "Epoch: 7 train Loss: 0.7532 Acc: 0.7313\n",
            "Epoch: 7 eval Loss: 0.9252 Acc: 0.6250\n",
            "Epoch: 8 train Loss: 0.7191 Acc: 0.7375\n",
            "Epoch: 8 eval Loss: 0.8109 Acc: 0.6250\n",
            "Epoch: 9 train Loss: 0.6711 Acc: 0.7500\n",
            "Epoch: 9 eval Loss: 0.7210 Acc: 0.7500\n",
            "Epoch: 10 train Loss: 0.6317 Acc: 0.7500\n",
            "Epoch: 10 eval Loss: 0.6985 Acc: 0.7500\n",
            "Epoch: 11 train Loss: 0.6024 Acc: 0.7625\n",
            "Epoch: 11 eval Loss: 0.6666 Acc: 0.7500\n",
            "Epoch: 12 train Loss: 0.5680 Acc: 0.7688\n",
            "Epoch: 12 eval Loss: 0.7663 Acc: 0.6250\n",
            "Epoch: 13 train Loss: 0.4971 Acc: 0.7750\n",
            "Epoch: 13 eval Loss: 1.3178 Acc: 0.5938\n",
            "Epoch: 14 train Loss: 0.4580 Acc: 0.7875\n",
            "Epoch: 14 eval Loss: 0.9948 Acc: 0.6250\n",
            "Epoch: 15 train Loss: 0.3877 Acc: 0.8250\n",
            "Epoch: 15 eval Loss: 0.9358 Acc: 0.6875\n",
            "Epoch: 16 train Loss: 0.3604 Acc: 0.8250\n",
            "Epoch: 16 eval Loss: 0.7719 Acc: 0.6250\n",
            "Epoch: 17 train Loss: 0.3285 Acc: 0.8563\n",
            "Epoch: 17 eval Loss: 1.7721 Acc: 0.6562\n",
            "Epoch: 18 train Loss: 0.7508 Acc: 0.7063\n",
            "Epoch: 18 eval Loss: 0.9673 Acc: 0.6250\n",
            "Epoch: 19 train Loss: 0.5858 Acc: 0.7938\n",
            "Epoch: 19 eval Loss: 4.3661 Acc: 0.5000\n",
            "Epoch: 20 train Loss: 0.5207 Acc: 0.7750\n",
            "Epoch: 20 eval Loss: 1.4175 Acc: 0.5938\n",
            "Epoch: 21 train Loss: 0.4481 Acc: 0.8125\n",
            "Epoch: 21 eval Loss: 0.9593 Acc: 0.6875\n",
            "Epoch: 22 train Loss: 0.4083 Acc: 0.8250\n",
            "Epoch: 22 eval Loss: 0.7537 Acc: 0.7188\n",
            "Epoch: 23 train Loss: 0.3853 Acc: 0.8125\n",
            "Epoch: 23 eval Loss: 0.8037 Acc: 0.6250\n",
            "Epoch: 24 train Loss: 0.3136 Acc: 0.8563\n",
            "Epoch: 24 eval Loss: 0.9481 Acc: 0.6875\n",
            "Epoch: 25 train Loss: 0.2794 Acc: 0.9000\n",
            "Epoch: 25 eval Loss: 1.2269 Acc: 0.6250\n",
            "Epoch: 26 train Loss: 0.2580 Acc: 0.9500\n",
            "Epoch: 26 eval Loss: 1.3571 Acc: 0.6562\n",
            "Epoch: 27 train Loss: 0.2324 Acc: 0.9438\n",
            "Epoch: 27 eval Loss: 1.4801 Acc: 0.6875\n",
            "Epoch: 28 train Loss: 0.1930 Acc: 0.9625\n",
            "Epoch: 28 eval Loss: 1.8296 Acc: 0.6250\n",
            "Epoch: 29 train Loss: 0.1683 Acc: 0.9625\n",
            "Epoch: 29 eval Loss: 1.8668 Acc: 0.6875\n",
            "Epoch: 30 train Loss: 0.1348 Acc: 0.9875\n",
            "Epoch: 30 eval Loss: 2.0223 Acc: 0.5938\n",
            "Epoch: 31 train Loss: 0.1254 Acc: 0.9688\n",
            "Epoch: 31 eval Loss: 2.0821 Acc: 0.5938\n",
            "Epoch: 32 train Loss: 0.0819 Acc: 0.9875\n",
            "Epoch: 32 eval Loss: 2.1886 Acc: 0.5312\n",
            "Epoch: 33 train Loss: 0.0743 Acc: 0.9875\n",
            "Epoch: 33 eval Loss: 2.1672 Acc: 0.5938\n",
            "Epoch: 34 train Loss: 0.0595 Acc: 0.9813\n",
            "Epoch: 34 eval Loss: 2.3934 Acc: 0.6250\n",
            "Epoch: 35 train Loss: 0.0490 Acc: 0.9875\n",
            "Epoch: 35 eval Loss: 2.1720 Acc: 0.6562\n",
            "Epoch: 36 train Loss: 0.1436 Acc: 0.9500\n",
            "Epoch: 36 eval Loss: 1.8481 Acc: 0.6250\n",
            "Epoch: 37 train Loss: 0.8373 Acc: 0.8438\n",
            "Epoch: 37 eval Loss: 2.5421 Acc: 0.3125\n",
            "Epoch: 38 train Loss: 0.6525 Acc: 0.7563\n",
            "Epoch: 38 eval Loss: 8.6857 Acc: 0.5312\n",
            "Epoch: 39 train Loss: 0.4724 Acc: 0.8625\n",
            "Epoch: 39 eval Loss: 6.2818 Acc: 0.5625\n",
            "Epoch: 40 train Loss: 0.2591 Acc: 0.9125\n",
            "Epoch: 40 eval Loss: 1.7597 Acc: 0.5625\n",
            "Epoch: 41 train Loss: 0.1977 Acc: 0.9563\n",
            "Epoch: 41 eval Loss: 1.0738 Acc: 0.5938\n",
            "Epoch: 42 train Loss: 0.1530 Acc: 0.9625\n",
            "Epoch: 42 eval Loss: 1.0700 Acc: 0.5938\n",
            "Epoch: 43 train Loss: 0.1082 Acc: 0.9813\n",
            "Epoch: 43 eval Loss: 0.8643 Acc: 0.6875\n",
            "Epoch: 44 train Loss: 0.1045 Acc: 0.9750\n",
            "Epoch: 44 eval Loss: 0.6910 Acc: 0.7188\n",
            "Epoch: 45 train Loss: 0.0875 Acc: 0.9813\n",
            "Epoch: 45 eval Loss: 0.6478 Acc: 0.7188\n",
            "Epoch: 46 train Loss: 0.0795 Acc: 0.9813\n",
            "Epoch: 46 eval Loss: 0.6863 Acc: 0.6875\n",
            "Epoch: 47 train Loss: 0.0511 Acc: 0.9875\n",
            "Epoch: 47 eval Loss: 0.7466 Acc: 0.6562\n",
            "Epoch: 48 train Loss: 0.0478 Acc: 0.9875\n",
            "Epoch: 48 eval Loss: 0.8187 Acc: 0.6250\n",
            "Epoch: 49 train Loss: 0.0313 Acc: 1.0000\n",
            "Epoch: 49 eval Loss: 0.9029 Acc: 0.5625\n",
            "Epoch: 50 train Loss: 0.0369 Acc: 0.9875\n",
            "Epoch: 50 eval Loss: 0.9155 Acc: 0.5625\n",
            "Epoch: 51 train Loss: 0.0196 Acc: 1.0000\n",
            "Epoch: 51 eval Loss: 0.9308 Acc: 0.5938\n",
            "Epoch: 52 train Loss: 0.0194 Acc: 1.0000\n",
            "Epoch: 52 eval Loss: 1.0061 Acc: 0.5938\n",
            "Epoch: 53 train Loss: 0.0117 Acc: 1.0000\n",
            "Epoch: 53 eval Loss: 1.1193 Acc: 0.5938\n",
            "Epoch: 54 train Loss: 0.0109 Acc: 1.0000\n",
            "Epoch: 54 eval Loss: 1.2061 Acc: 0.5625\n",
            "Epoch: 55 train Loss: 0.0071 Acc: 1.0000\n",
            "Epoch: 55 eval Loss: 1.2674 Acc: 0.5625\n",
            "Epoch: 56 train Loss: 0.0071 Acc: 1.0000\n",
            "Epoch: 56 eval Loss: 1.2891 Acc: 0.5625\n",
            "Epoch: 57 train Loss: 0.0053 Acc: 1.0000\n",
            "Epoch: 57 eval Loss: 1.2995 Acc: 0.5625\n",
            "Epoch: 58 train Loss: 0.0049 Acc: 1.0000\n",
            "Epoch: 58 eval Loss: 1.3036 Acc: 0.5625\n",
            "Epoch: 59 train Loss: 0.0046 Acc: 1.0000\n",
            "Epoch: 59 eval Loss: 1.2902 Acc: 0.5625\n",
            "Epoch: 60 train Loss: 0.0033 Acc: 1.0000\n",
            "Epoch: 60 eval Loss: 1.2802 Acc: 0.5625\n",
            "Epoch: 61 train Loss: 0.0031 Acc: 1.0000\n",
            "Epoch: 61 eval Loss: 1.2811 Acc: 0.5625\n",
            "Epoch: 62 train Loss: 0.0027 Acc: 1.0000\n",
            "Epoch: 62 eval Loss: 1.2892 Acc: 0.5625\n",
            "Epoch: 63 train Loss: 0.0024 Acc: 1.0000\n",
            "Epoch: 63 eval Loss: 1.3007 Acc: 0.5312\n",
            "Epoch: 64 train Loss: 0.0019 Acc: 1.0000\n",
            "Epoch: 64 eval Loss: 1.3136 Acc: 0.5312\n",
            "Epoch: 65 train Loss: 0.0022 Acc: 1.0000\n",
            "Epoch: 65 eval Loss: 1.3281 Acc: 0.5312\n",
            "Epoch: 66 train Loss: 0.0022 Acc: 1.0000\n",
            "Epoch: 66 eval Loss: 1.3414 Acc: 0.5312\n",
            "Epoch: 67 train Loss: 0.0020 Acc: 1.0000\n",
            "Epoch: 67 eval Loss: 1.3530 Acc: 0.5312\n",
            "Epoch: 68 train Loss: 0.0017 Acc: 1.0000\n",
            "Epoch: 68 eval Loss: 1.3617 Acc: 0.5312\n",
            "Epoch: 69 train Loss: 0.0017 Acc: 1.0000\n",
            "Epoch: 69 eval Loss: 1.3727 Acc: 0.5312\n",
            "Epoch: 70 train Loss: 0.0017 Acc: 1.0000\n",
            "Epoch: 70 eval Loss: 1.3895 Acc: 0.5312\n",
            "Epoch: 71 train Loss: 0.0014 Acc: 1.0000\n",
            "Epoch: 71 eval Loss: 1.4082 Acc: 0.5312\n",
            "Epoch: 72 train Loss: 0.0013 Acc: 1.0000\n",
            "Epoch: 72 eval Loss: 1.4218 Acc: 0.5312\n",
            "Epoch: 73 train Loss: 0.0015 Acc: 1.0000\n",
            "Epoch: 73 eval Loss: 1.4283 Acc: 0.5312\n",
            "Epoch: 74 train Loss: 0.0012 Acc: 1.0000\n",
            "Epoch: 74 eval Loss: 1.4320 Acc: 0.5312\n",
            "Epoch: 75 train Loss: 0.0011 Acc: 1.0000\n",
            "Epoch: 75 eval Loss: 1.4334 Acc: 0.5312\n",
            "Epoch: 76 train Loss: 0.0014 Acc: 1.0000\n",
            "Epoch: 76 eval Loss: 1.4358 Acc: 0.5312\n",
            "Epoch: 77 train Loss: 0.0011 Acc: 1.0000\n",
            "Epoch: 77 eval Loss: 1.4373 Acc: 0.5312\n",
            "Epoch: 78 train Loss: 0.0013 Acc: 1.0000\n",
            "Epoch: 78 eval Loss: 1.4357 Acc: 0.5312\n",
            "Epoch: 79 train Loss: 0.0012 Acc: 1.0000\n",
            "Epoch: 79 eval Loss: 1.4314 Acc: 0.5312\n",
            "Epoch: 80 train Loss: 0.0012 Acc: 1.0000\n",
            "Epoch: 80 eval Loss: 1.4302 Acc: 0.5312\n",
            "Epoch: 81 train Loss: 0.0010 Acc: 1.0000\n",
            "Epoch: 81 eval Loss: 1.4352 Acc: 0.5312\n",
            "Epoch: 82 train Loss: 0.0011 Acc: 1.0000\n",
            "Epoch: 82 eval Loss: 1.4396 Acc: 0.5312\n",
            "Epoch: 83 train Loss: 0.0009 Acc: 1.0000\n",
            "Epoch: 83 eval Loss: 1.4430 Acc: 0.5312\n",
            "Epoch: 84 train Loss: 0.0008 Acc: 1.0000\n",
            "Epoch: 84 eval Loss: 1.4442 Acc: 0.5312\n",
            "Epoch: 85 train Loss: 0.0008 Acc: 1.0000\n",
            "Epoch: 85 eval Loss: 1.4449 Acc: 0.5312\n",
            "Epoch: 86 train Loss: 0.0007 Acc: 1.0000\n",
            "Epoch: 86 eval Loss: 1.4467 Acc: 0.5312\n",
            "Epoch: 87 train Loss: 0.0007 Acc: 1.0000\n",
            "Epoch: 87 eval Loss: 1.4477 Acc: 0.5312\n",
            "Epoch: 88 train Loss: 0.0007 Acc: 1.0000\n",
            "Epoch: 88 eval Loss: 1.4454 Acc: 0.5312\n",
            "Epoch: 89 train Loss: 0.0008 Acc: 1.0000\n",
            "Epoch: 89 eval Loss: 1.4419 Acc: 0.5312\n",
            "Epoch: 90 train Loss: 0.0007 Acc: 1.0000\n",
            "Epoch: 90 eval Loss: 1.4398 Acc: 0.5312\n",
            "Epoch: 91 train Loss: 0.0008 Acc: 1.0000\n",
            "Epoch: 91 eval Loss: 1.4404 Acc: 0.5312\n",
            "Epoch: 92 train Loss: 0.0008 Acc: 1.0000\n",
            "Epoch: 92 eval Loss: 1.4425 Acc: 0.5312\n",
            "Epoch: 93 train Loss: 0.0006 Acc: 1.0000\n",
            "Epoch: 93 eval Loss: 1.4456 Acc: 0.5312\n",
            "Epoch: 94 train Loss: 0.0007 Acc: 1.0000\n",
            "Epoch: 94 eval Loss: 1.4473 Acc: 0.5312\n",
            "Epoch: 95 train Loss: 0.0007 Acc: 1.0000\n",
            "Epoch: 95 eval Loss: 1.4495 Acc: 0.5312\n",
            "Epoch: 96 train Loss: 0.0009 Acc: 1.0000\n",
            "Epoch: 96 eval Loss: 1.4492 Acc: 0.5312\n",
            "Epoch: 97 train Loss: 0.0008 Acc: 1.0000\n",
            "Epoch: 97 eval Loss: 1.4478 Acc: 0.5312\n",
            "Epoch: 98 train Loss: 0.0007 Acc: 1.0000\n",
            "Epoch: 98 eval Loss: 1.4471 Acc: 0.5312\n",
            "Epoch: 99 train Loss: 0.0008 Acc: 1.0000\n",
            "Epoch: 99 eval Loss: 1.4469 Acc: 0.5312\n",
            "Fold 2 accuracy: 0.75 achieved in epoch 9\n",
            "Train:  [  0   1   2   3   4   5   6   8   9  10  11  12  13  14  16  17  18  19\n",
            "  20  21  23  24  26  27  28  29  30  31  32  34  36  37  38  39  40  41\n",
            "  42  43  45  46  47  48  50  51  54  55  56  57  58  59  60  61  62  65\n",
            "  66  67  68  69  70  71  72  73  74  75  76  78  79  81  82  83  84  85\n",
            "  86  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104\n",
            " 105 106 108 110 111 113 114 116 117 118 119 120 121 122 124 125 126 128\n",
            " 129 130 131 132 133 134 135 137 138 141 142 143 144 145 146 147 148 149\n",
            " 150 151 153 156 157 158 160 161 162 163 164 165 166 167 168 169 171 172\n",
            " 173 176 177 178 179 181 182 183 184 185 186 187 188 189 190 191] Validation:  [  7  15  22  25  33  35  44  49  52  53  63  64  77  80  87 107 109 112\n",
            " 115 123 127 136 139 140 152 154 155 159 170 174 175 180]\n",
            "Epoch: 0 train Loss: 7.2498 Acc: 0.1375\n",
            "Epoch: 0 eval Loss: 2.0443 Acc: 0.3125\n",
            "Epoch: 1 train Loss: 1.1458 Acc: 0.2687\n",
            "Epoch: 1 eval Loss: 1.5820 Acc: 0.3125\n",
            "Epoch: 2 train Loss: 1.0533 Acc: 0.3938\n",
            "Epoch: 2 eval Loss: 1.9356 Acc: 0.3125\n",
            "Epoch: 3 train Loss: 0.9618 Acc: 0.5687\n",
            "Epoch: 3 eval Loss: 3.3517 Acc: 0.3125\n",
            "Epoch: 4 train Loss: 0.7600 Acc: 0.6625\n",
            "Epoch: 4 eval Loss: 3.1348 Acc: 0.4062\n",
            "Epoch: 5 train Loss: 0.5441 Acc: 0.7563\n",
            "Epoch: 5 eval Loss: 4.9184 Acc: 0.4688\n",
            "Epoch: 6 train Loss: 0.3083 Acc: 0.8375\n",
            "Epoch: 6 eval Loss: 0.9997 Acc: 0.6562\n",
            "Epoch: 7 train Loss: 0.2115 Acc: 0.9438\n",
            "Epoch: 7 eval Loss: 0.8131 Acc: 0.7500\n",
            "Epoch: 8 train Loss: 0.0870 Acc: 0.9688\n",
            "Epoch: 8 eval Loss: 0.6050 Acc: 0.6875\n",
            "Epoch: 9 train Loss: 0.0729 Acc: 0.9813\n",
            "Epoch: 9 eval Loss: 2.8392 Acc: 0.7188\n",
            "Epoch: 10 train Loss: 0.0313 Acc: 0.9875\n",
            "Epoch: 10 eval Loss: 0.6761 Acc: 0.8125\n",
            "Epoch: 11 train Loss: 0.0432 Acc: 0.9813\n",
            "Epoch: 11 eval Loss: 2.7883 Acc: 0.7500\n",
            "Epoch: 12 train Loss: 0.7472 Acc: 0.8563\n",
            "Epoch: 12 eval Loss: 13.4614 Acc: 0.6250\n",
            "Epoch: 13 train Loss: 0.3160 Acc: 0.9125\n",
            "Epoch: 13 eval Loss: 3.7378 Acc: 0.6875\n",
            "Epoch: 14 train Loss: 0.2909 Acc: 0.9062\n",
            "Epoch: 14 eval Loss: 0.9680 Acc: 0.7500\n",
            "Epoch: 15 train Loss: 0.1733 Acc: 0.9500\n",
            "Epoch: 15 eval Loss: 0.9395 Acc: 0.7188\n",
            "Epoch: 16 train Loss: 0.0488 Acc: 0.9875\n",
            "Epoch: 16 eval Loss: 1.4165 Acc: 0.8750\n",
            "Epoch: 17 train Loss: 0.0200 Acc: 1.0000\n",
            "Epoch: 17 eval Loss: 1.4802 Acc: 0.8750\n",
            "Epoch: 18 train Loss: 0.0062 Acc: 1.0000\n",
            "Epoch: 18 eval Loss: 1.2438 Acc: 0.8750\n",
            "Epoch: 19 train Loss: 0.0034 Acc: 1.0000\n",
            "Epoch: 19 eval Loss: 1.1073 Acc: 0.7812\n",
            "Epoch: 20 train Loss: 0.0023 Acc: 1.0000\n",
            "Epoch: 20 eval Loss: 1.0640 Acc: 0.7812\n",
            "Epoch: 21 train Loss: 0.0030 Acc: 1.0000\n",
            "Epoch: 21 eval Loss: 0.9160 Acc: 0.8125\n",
            "Epoch: 22 train Loss: 0.0011 Acc: 1.0000\n",
            "Epoch: 22 eval Loss: 0.7516 Acc: 0.8125\n",
            "Epoch: 23 train Loss: 0.0005 Acc: 1.0000\n",
            "Epoch: 23 eval Loss: 0.6811 Acc: 0.7812\n",
            "Epoch: 24 train Loss: 0.0004 Acc: 1.0000\n",
            "Epoch: 24 eval Loss: 0.6879 Acc: 0.7812\n",
            "Epoch: 25 train Loss: 0.0004 Acc: 1.0000\n",
            "Epoch: 25 eval Loss: 0.7082 Acc: 0.7500\n",
            "Epoch: 26 train Loss: 0.0005 Acc: 1.0000\n",
            "Epoch: 26 eval Loss: 0.7353 Acc: 0.7812\n",
            "Epoch: 27 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 27 eval Loss: 0.7561 Acc: 0.7812\n",
            "Epoch: 28 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 28 eval Loss: 0.7680 Acc: 0.7812\n",
            "Epoch: 29 train Loss: 0.0008 Acc: 1.0000\n",
            "Epoch: 29 eval Loss: 0.7759 Acc: 0.7812\n",
            "Epoch: 30 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 30 eval Loss: 0.7836 Acc: 0.7812\n",
            "Epoch: 31 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 31 eval Loss: 0.7890 Acc: 0.7812\n",
            "Epoch: 32 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 32 eval Loss: 0.7914 Acc: 0.7812\n",
            "Epoch: 33 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 33 eval Loss: 0.7931 Acc: 0.7812\n",
            "Epoch: 34 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 34 eval Loss: 0.7950 Acc: 0.7812\n",
            "Epoch: 35 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 35 eval Loss: 0.7968 Acc: 0.7812\n",
            "Epoch: 36 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 36 eval Loss: 0.7959 Acc: 0.7812\n",
            "Epoch: 37 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 37 eval Loss: 0.7943 Acc: 0.7812\n",
            "Epoch: 38 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 38 eval Loss: 0.7941 Acc: 0.7812\n",
            "Epoch: 39 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 39 eval Loss: 0.7945 Acc: 0.7812\n",
            "Epoch: 40 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 40 eval Loss: 0.7937 Acc: 0.7812\n",
            "Epoch: 41 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 41 eval Loss: 0.7907 Acc: 0.7812\n",
            "Epoch: 42 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 42 eval Loss: 0.7873 Acc: 0.7812\n",
            "Epoch: 43 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 43 eval Loss: 0.7844 Acc: 0.7812\n",
            "Epoch: 44 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 44 eval Loss: 0.7830 Acc: 0.7812\n",
            "Epoch: 45 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 45 eval Loss: 0.7823 Acc: 0.7812\n",
            "Epoch: 46 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 46 eval Loss: 0.7819 Acc: 0.7812\n",
            "Epoch: 47 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 47 eval Loss: 0.7809 Acc: 0.7812\n",
            "Epoch: 48 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 48 eval Loss: 0.7798 Acc: 0.7812\n",
            "Epoch: 49 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 49 eval Loss: 0.7790 Acc: 0.7812\n",
            "Epoch: 50 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 50 eval Loss: 0.7790 Acc: 0.7812\n",
            "Epoch: 51 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 51 eval Loss: 0.7792 Acc: 0.7812\n",
            "Epoch: 52 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 52 eval Loss: 0.7794 Acc: 0.7812\n",
            "Epoch: 53 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 53 eval Loss: 0.7795 Acc: 0.7812\n",
            "Epoch: 54 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 54 eval Loss: 0.7793 Acc: 0.7812\n",
            "Epoch: 55 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 55 eval Loss: 0.7795 Acc: 0.7812\n",
            "Epoch: 56 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 56 eval Loss: 0.7800 Acc: 0.7812\n",
            "Epoch: 57 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 57 eval Loss: 0.7804 Acc: 0.7812\n",
            "Epoch: 58 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 58 eval Loss: 0.7806 Acc: 0.7812\n",
            "Epoch: 59 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 59 eval Loss: 0.7805 Acc: 0.7812\n",
            "Epoch: 60 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 60 eval Loss: 0.7810 Acc: 0.7812\n",
            "Epoch: 61 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 61 eval Loss: 0.7814 Acc: 0.7812\n",
            "Epoch: 62 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 62 eval Loss: 0.7835 Acc: 0.7812\n",
            "Epoch: 63 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 63 eval Loss: 0.7855 Acc: 0.7812\n",
            "Epoch: 64 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 64 eval Loss: 0.7869 Acc: 0.7812\n",
            "Epoch: 65 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 65 eval Loss: 0.7883 Acc: 0.7812\n",
            "Epoch: 66 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 66 eval Loss: 0.7900 Acc: 0.7812\n",
            "Epoch: 67 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 67 eval Loss: 0.7914 Acc: 0.7812\n",
            "Epoch: 68 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 68 eval Loss: 0.7926 Acc: 0.7812\n",
            "Epoch: 69 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 69 eval Loss: 0.7932 Acc: 0.7812\n",
            "Epoch: 70 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 70 eval Loss: 0.7936 Acc: 0.7812\n",
            "Epoch: 71 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 71 eval Loss: 0.7939 Acc: 0.7812\n",
            "Epoch: 72 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 72 eval Loss: 0.7936 Acc: 0.7812\n",
            "Epoch: 73 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 73 eval Loss: 0.7924 Acc: 0.7812\n",
            "Epoch: 74 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 74 eval Loss: 0.7918 Acc: 0.7812\n",
            "Epoch: 75 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 75 eval Loss: 0.7916 Acc: 0.7812\n",
            "Epoch: 76 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 76 eval Loss: 0.7916 Acc: 0.7812\n",
            "Epoch: 77 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 77 eval Loss: 0.7916 Acc: 0.7812\n",
            "Epoch: 78 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 78 eval Loss: 0.7915 Acc: 0.7812\n",
            "Epoch: 79 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 79 eval Loss: 0.7911 Acc: 0.7812\n",
            "Epoch: 80 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 80 eval Loss: 0.7905 Acc: 0.7812\n",
            "Epoch: 81 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 81 eval Loss: 0.7901 Acc: 0.7812\n",
            "Epoch: 82 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 82 eval Loss: 0.7896 Acc: 0.7812\n",
            "Epoch: 83 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 83 eval Loss: 0.7896 Acc: 0.7812\n",
            "Epoch: 84 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 84 eval Loss: 0.7898 Acc: 0.7812\n",
            "Epoch: 85 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 85 eval Loss: 0.7900 Acc: 0.8125\n",
            "Epoch: 86 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 86 eval Loss: 0.7902 Acc: 0.8125\n",
            "Epoch: 87 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 87 eval Loss: 0.7905 Acc: 0.8125\n",
            "Epoch: 88 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 88 eval Loss: 0.7908 Acc: 0.8125\n",
            "Epoch: 89 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 89 eval Loss: 0.7910 Acc: 0.8125\n",
            "Epoch: 90 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 90 eval Loss: 0.7911 Acc: 0.8125\n",
            "Epoch: 91 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 91 eval Loss: 0.7912 Acc: 0.8125\n",
            "Epoch: 92 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 92 eval Loss: 0.7914 Acc: 0.8125\n",
            "Epoch: 93 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 93 eval Loss: 0.7914 Acc: 0.8125\n",
            "Epoch: 94 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 94 eval Loss: 0.7913 Acc: 0.8125\n",
            "Epoch: 95 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 95 eval Loss: 0.7913 Acc: 0.8125\n",
            "Epoch: 96 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 96 eval Loss: 0.7911 Acc: 0.8125\n",
            "Epoch: 97 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 97 eval Loss: 0.7910 Acc: 0.8125\n",
            "Epoch: 98 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 98 eval Loss: 0.7912 Acc: 0.8125\n",
            "Epoch: 99 train Loss: 0.0000 Acc: 1.0000\n",
            "Epoch: 99 eval Loss: 0.7911 Acc: 0.8125\n",
            "Fold 3 accuracy: 0.875 achieved in epoch 16\n",
            "Train:  [  0   1   3   5   6   7   8   9  10  11  12  14  15  16  17  18  22  23\n",
            "  24  25  26  27  28  29  30  33  34  35  36  38  39  40  41  42  43  44\n",
            "  45  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63\n",
            "  64  65  66  67  68  69  70  71  72  73  74  77  78  79  80  82  83  84\n",
            "  85  87  88  91  92  93  94  96  97  98 100 101 102 103 104 106 107 108\n",
            " 109 110 111 112 114 115 116 117 118 119 120 122 123 124 125 126 127 128\n",
            " 129 130 131 133 134 136 137 138 139 140 141 142 144 146 147 148 149 150\n",
            " 151 152 153 154 155 156 157 158 159 161 163 165 167 168 169 170 172 174\n",
            " 175 176 177 178 179 180 181 182 183 184 185 186 187 189 190 191] Validation:  [  2   4  13  19  20  21  31  32  37  46  75  76  81  86  89  90  95  99\n",
            " 105 113 121 132 135 143 145 160 162 164 166 171 173 188]\n",
            "Epoch: 0 train Loss: 6.5235 Acc: 0.1875\n",
            "Epoch: 0 eval Loss: 11.2029 Acc: 0.3438\n",
            "Epoch: 1 train Loss: 1.1030 Acc: 0.2500\n",
            "Epoch: 1 eval Loss: 1.7815 Acc: 0.3438\n",
            "Epoch: 2 train Loss: 1.0551 Acc: 0.5687\n",
            "Epoch: 2 eval Loss: 1.5467 Acc: 0.3750\n",
            "Epoch: 3 train Loss: 0.9913 Acc: 0.6125\n",
            "Epoch: 3 eval Loss: 0.7723 Acc: 0.6562\n",
            "Epoch: 4 train Loss: 0.8913 Acc: 0.6188\n",
            "Epoch: 4 eval Loss: 1.7052 Acc: 0.5938\n",
            "Epoch: 5 train Loss: 0.7820 Acc: 0.6875\n",
            "Epoch: 5 eval Loss: 1.9093 Acc: 0.6250\n",
            "Epoch: 6 train Loss: 0.6211 Acc: 0.8063\n",
            "Epoch: 6 eval Loss: 1.5090 Acc: 0.6562\n",
            "Epoch: 7 train Loss: 0.4936 Acc: 0.8125\n",
            "Epoch: 7 eval Loss: 1.1062 Acc: 0.7188\n",
            "Epoch: 8 train Loss: 0.3829 Acc: 0.8313\n",
            "Epoch: 8 eval Loss: 0.5906 Acc: 0.7500\n",
            "Epoch: 9 train Loss: 0.3072 Acc: 0.8625\n",
            "Epoch: 9 eval Loss: 0.7147 Acc: 0.7500\n",
            "Epoch: 10 train Loss: 0.2318 Acc: 0.8938\n",
            "Epoch: 10 eval Loss: 2.2004 Acc: 0.7188\n",
            "Epoch: 11 train Loss: 0.2019 Acc: 0.9375\n",
            "Epoch: 11 eval Loss: 1.5210 Acc: 0.7500\n",
            "Epoch: 12 train Loss: 0.1506 Acc: 0.9500\n",
            "Epoch: 12 eval Loss: 1.9459 Acc: 0.7188\n",
            "Epoch: 13 train Loss: 0.1261 Acc: 0.9500\n",
            "Epoch: 13 eval Loss: 1.4291 Acc: 0.6562\n",
            "Epoch: 14 train Loss: 0.2955 Acc: 0.9188\n",
            "Epoch: 14 eval Loss: 2.0363 Acc: 0.7188\n",
            "Epoch: 15 train Loss: 0.2379 Acc: 0.9250\n",
            "Epoch: 15 eval Loss: 2.4007 Acc: 0.7812\n",
            "Epoch: 16 train Loss: 0.2728 Acc: 0.9062\n",
            "Epoch: 16 eval Loss: 1.6293 Acc: 0.8125\n",
            "Epoch: 17 train Loss: 0.1499 Acc: 0.9438\n",
            "Epoch: 17 eval Loss: 0.9242 Acc: 0.7188\n",
            "Epoch: 18 train Loss: 0.4482 Acc: 0.8625\n",
            "Epoch: 18 eval Loss: 1.3264 Acc: 0.6875\n",
            "Epoch: 19 train Loss: 0.4242 Acc: 0.8688\n",
            "Epoch: 19 eval Loss: 1.4897 Acc: 0.5312\n",
            "Epoch: 20 train Loss: 0.1231 Acc: 0.9563\n",
            "Epoch: 20 eval Loss: 1.0237 Acc: 0.7188\n",
            "Epoch: 21 train Loss: 0.2514 Acc: 0.9438\n",
            "Epoch: 21 eval Loss: 1.7770 Acc: 0.6250\n",
            "Epoch: 22 train Loss: 0.1047 Acc: 0.9625\n",
            "Epoch: 22 eval Loss: 2.2400 Acc: 0.6250\n",
            "Epoch: 23 train Loss: 0.0829 Acc: 0.9750\n",
            "Epoch: 23 eval Loss: 1.8975 Acc: 0.6562\n",
            "Epoch: 24 train Loss: 0.0717 Acc: 0.9750\n",
            "Epoch: 24 eval Loss: 1.2724 Acc: 0.7500\n",
            "Epoch: 25 train Loss: 0.0597 Acc: 0.9813\n",
            "Epoch: 25 eval Loss: 0.8278 Acc: 0.7188\n",
            "Epoch: 26 train Loss: 0.0480 Acc: 0.9875\n",
            "Epoch: 26 eval Loss: 0.6774 Acc: 0.8125\n",
            "Epoch: 27 train Loss: 0.0432 Acc: 0.9875\n",
            "Epoch: 27 eval Loss: 0.6700 Acc: 0.7812\n",
            "Epoch: 28 train Loss: 0.0434 Acc: 0.9875\n",
            "Epoch: 28 eval Loss: 0.6980 Acc: 0.7812\n",
            "Epoch: 29 train Loss: 0.0392 Acc: 0.9875\n",
            "Epoch: 29 eval Loss: 0.7177 Acc: 0.7812\n",
            "Epoch: 30 train Loss: 0.0401 Acc: 0.9875\n",
            "Epoch: 30 eval Loss: 0.7381 Acc: 0.7500\n",
            "Epoch: 31 train Loss: 0.0341 Acc: 0.9875\n",
            "Epoch: 31 eval Loss: 0.7587 Acc: 0.7500\n",
            "Epoch: 32 train Loss: 0.0302 Acc: 0.9875\n",
            "Epoch: 32 eval Loss: 0.7785 Acc: 0.7500\n",
            "Epoch: 33 train Loss: 0.0294 Acc: 0.9875\n",
            "Epoch: 33 eval Loss: 0.8047 Acc: 0.7500\n",
            "Epoch: 34 train Loss: 0.0281 Acc: 0.9875\n",
            "Epoch: 34 eval Loss: 0.8355 Acc: 0.7500\n",
            "Epoch: 35 train Loss: 0.0264 Acc: 0.9875\n",
            "Epoch: 35 eval Loss: 0.8619 Acc: 0.7188\n",
            "Epoch: 36 train Loss: 0.0251 Acc: 0.9875\n",
            "Epoch: 36 eval Loss: 0.8885 Acc: 0.7188\n",
            "Epoch: 37 train Loss: 0.0209 Acc: 0.9875\n",
            "Epoch: 37 eval Loss: 0.9243 Acc: 0.7188\n",
            "Epoch: 38 train Loss: 0.0203 Acc: 0.9875\n",
            "Epoch: 38 eval Loss: 0.9679 Acc: 0.6875\n",
            "Epoch: 39 train Loss: 0.0154 Acc: 0.9875\n",
            "Epoch: 39 eval Loss: 1.0095 Acc: 0.6875\n",
            "Epoch: 40 train Loss: 0.0183 Acc: 0.9875\n",
            "Epoch: 40 eval Loss: 1.0472 Acc: 0.6875\n",
            "Epoch: 41 train Loss: 0.0155 Acc: 0.9875\n",
            "Epoch: 41 eval Loss: 1.0792 Acc: 0.7500\n",
            "Epoch: 42 train Loss: 0.0124 Acc: 0.9875\n",
            "Epoch: 42 eval Loss: 1.1060 Acc: 0.7500\n",
            "Epoch: 43 train Loss: 0.0119 Acc: 0.9875\n",
            "Epoch: 43 eval Loss: 1.1273 Acc: 0.7500\n",
            "Epoch: 44 train Loss: 0.0121 Acc: 0.9875\n",
            "Epoch: 44 eval Loss: 1.1479 Acc: 0.7500\n",
            "Epoch: 45 train Loss: 0.0107 Acc: 0.9875\n",
            "Epoch: 45 eval Loss: 1.1686 Acc: 0.7500\n",
            "Epoch: 46 train Loss: 0.0102 Acc: 0.9938\n",
            "Epoch: 46 eval Loss: 1.1882 Acc: 0.7500\n",
            "Epoch: 47 train Loss: 0.0086 Acc: 1.0000\n",
            "Epoch: 47 eval Loss: 1.2110 Acc: 0.7500\n",
            "Epoch: 48 train Loss: 0.0091 Acc: 1.0000\n",
            "Epoch: 48 eval Loss: 1.2303 Acc: 0.7500\n",
            "Epoch: 49 train Loss: 0.0071 Acc: 1.0000\n",
            "Epoch: 49 eval Loss: 1.2457 Acc: 0.7500\n",
            "Epoch: 50 train Loss: 0.0074 Acc: 1.0000\n",
            "Epoch: 50 eval Loss: 1.2591 Acc: 0.7500\n",
            "Epoch: 51 train Loss: 0.0070 Acc: 1.0000\n",
            "Epoch: 51 eval Loss: 1.2694 Acc: 0.7500\n",
            "Epoch: 52 train Loss: 0.0073 Acc: 1.0000\n",
            "Epoch: 52 eval Loss: 1.2781 Acc: 0.7500\n",
            "Epoch: 53 train Loss: 0.0048 Acc: 1.0000\n",
            "Epoch: 53 eval Loss: 1.2888 Acc: 0.7500\n",
            "Epoch: 54 train Loss: 0.0055 Acc: 1.0000\n",
            "Epoch: 54 eval Loss: 1.2999 Acc: 0.7500\n",
            "Epoch: 55 train Loss: 0.0057 Acc: 1.0000\n",
            "Epoch: 55 eval Loss: 1.3076 Acc: 0.7500\n",
            "Epoch: 56 train Loss: 0.0048 Acc: 1.0000\n",
            "Epoch: 56 eval Loss: 1.3178 Acc: 0.7500\n",
            "Epoch: 57 train Loss: 0.0038 Acc: 1.0000\n",
            "Epoch: 57 eval Loss: 1.2983 Acc: 0.7500\n",
            "Epoch: 58 train Loss: 0.0044 Acc: 1.0000\n",
            "Epoch: 58 eval Loss: 1.2842 Acc: 0.7500\n",
            "Epoch: 59 train Loss: 0.0045 Acc: 1.0000\n",
            "Epoch: 59 eval Loss: 1.2752 Acc: 0.7500\n",
            "Epoch: 60 train Loss: 0.0045 Acc: 1.0000\n",
            "Epoch: 60 eval Loss: 1.2723 Acc: 0.7500\n",
            "Epoch: 61 train Loss: 0.0030 Acc: 1.0000\n",
            "Epoch: 61 eval Loss: 1.2730 Acc: 0.7500\n",
            "Epoch: 62 train Loss: 0.0030 Acc: 1.0000\n",
            "Epoch: 62 eval Loss: 1.2748 Acc: 0.7500\n",
            "Epoch: 63 train Loss: 0.0035 Acc: 1.0000\n",
            "Epoch: 63 eval Loss: 1.2783 Acc: 0.7500\n",
            "Epoch: 64 train Loss: 0.0028 Acc: 1.0000\n",
            "Epoch: 64 eval Loss: 1.2840 Acc: 0.7500\n",
            "Epoch: 65 train Loss: 0.0024 Acc: 1.0000\n",
            "Epoch: 65 eval Loss: 1.2898 Acc: 0.7500\n",
            "Epoch: 66 train Loss: 0.0028 Acc: 1.0000\n",
            "Epoch: 66 eval Loss: 1.2979 Acc: 0.7500\n",
            "Epoch: 67 train Loss: 0.0028 Acc: 1.0000\n",
            "Epoch: 67 eval Loss: 1.3082 Acc: 0.7500\n",
            "Epoch: 68 train Loss: 0.0028 Acc: 1.0000\n",
            "Epoch: 68 eval Loss: 1.3182 Acc: 0.7500\n",
            "Epoch: 69 train Loss: 0.0031 Acc: 1.0000\n",
            "Epoch: 69 eval Loss: 1.3284 Acc: 0.7500\n",
            "Epoch: 70 train Loss: 0.0020 Acc: 1.0000\n",
            "Epoch: 70 eval Loss: 1.3422 Acc: 0.7188\n",
            "Epoch: 71 train Loss: 0.0022 Acc: 1.0000\n",
            "Epoch: 71 eval Loss: 1.3553 Acc: 0.7188\n",
            "Epoch: 72 train Loss: 0.0021 Acc: 1.0000\n",
            "Epoch: 72 eval Loss: 1.3664 Acc: 0.7188\n",
            "Epoch: 73 train Loss: 0.0019 Acc: 1.0000\n",
            "Epoch: 73 eval Loss: 1.3766 Acc: 0.7188\n",
            "Epoch: 74 train Loss: 0.0026 Acc: 1.0000\n",
            "Epoch: 74 eval Loss: 1.3848 Acc: 0.7500\n",
            "Epoch: 75 train Loss: 0.0030 Acc: 1.0000\n",
            "Epoch: 75 eval Loss: 1.3919 Acc: 0.7500\n",
            "Epoch: 76 train Loss: 0.0019 Acc: 1.0000\n",
            "Epoch: 76 eval Loss: 1.4001 Acc: 0.7500\n",
            "Epoch: 77 train Loss: 0.0017 Acc: 1.0000\n",
            "Epoch: 77 eval Loss: 1.4077 Acc: 0.7500\n",
            "Epoch: 78 train Loss: 0.0016 Acc: 1.0000\n",
            "Epoch: 78 eval Loss: 1.4142 Acc: 0.7500\n",
            "Epoch: 79 train Loss: 0.0017 Acc: 1.0000\n",
            "Epoch: 79 eval Loss: 1.4205 Acc: 0.7500\n",
            "Epoch: 80 train Loss: 0.0013 Acc: 1.0000\n",
            "Epoch: 80 eval Loss: 1.4293 Acc: 0.7500\n",
            "Epoch: 81 train Loss: 0.0016 Acc: 1.0000\n",
            "Epoch: 81 eval Loss: 1.4378 Acc: 0.7500\n",
            "Epoch: 82 train Loss: 0.0013 Acc: 1.0000\n",
            "Epoch: 82 eval Loss: 1.4474 Acc: 0.7500\n",
            "Epoch: 83 train Loss: 0.0016 Acc: 1.0000\n",
            "Epoch: 83 eval Loss: 1.4548 Acc: 0.7500\n",
            "Epoch: 84 train Loss: 0.0021 Acc: 1.0000\n",
            "Epoch: 84 eval Loss: 1.4615 Acc: 0.7500\n",
            "Epoch: 85 train Loss: 0.0009 Acc: 1.0000\n",
            "Epoch: 85 eval Loss: 1.4682 Acc: 0.7500\n",
            "Epoch: 86 train Loss: 0.0019 Acc: 1.0000\n",
            "Epoch: 86 eval Loss: 1.4747 Acc: 0.7500\n",
            "Epoch: 87 train Loss: 0.0011 Acc: 1.0000\n",
            "Epoch: 87 eval Loss: 1.4807 Acc: 0.7500\n",
            "Epoch: 88 train Loss: 0.0012 Acc: 1.0000\n",
            "Epoch: 88 eval Loss: 1.4857 Acc: 0.7500\n",
            "Epoch: 89 train Loss: 0.0010 Acc: 1.0000\n",
            "Epoch: 89 eval Loss: 1.4904 Acc: 0.7500\n",
            "Epoch: 90 train Loss: 0.0008 Acc: 1.0000\n",
            "Epoch: 90 eval Loss: 1.4947 Acc: 0.7812\n",
            "Epoch: 91 train Loss: 0.0017 Acc: 1.0000\n",
            "Epoch: 91 eval Loss: 1.4989 Acc: 0.7812\n",
            "Epoch: 92 train Loss: 0.0015 Acc: 1.0000\n",
            "Epoch: 92 eval Loss: 1.5031 Acc: 0.7812\n",
            "Epoch: 93 train Loss: 0.0012 Acc: 1.0000\n",
            "Epoch: 93 eval Loss: 1.5069 Acc: 0.7812\n",
            "Epoch: 94 train Loss: 0.0015 Acc: 1.0000\n",
            "Epoch: 94 eval Loss: 1.5103 Acc: 0.7812\n",
            "Epoch: 95 train Loss: 0.0013 Acc: 1.0000\n",
            "Epoch: 95 eval Loss: 1.5146 Acc: 0.7812\n",
            "Epoch: 96 train Loss: 0.0009 Acc: 1.0000\n",
            "Epoch: 96 eval Loss: 1.5190 Acc: 0.7812\n",
            "Epoch: 97 train Loss: 0.0012 Acc: 1.0000\n",
            "Epoch: 97 eval Loss: 1.5226 Acc: 0.7812\n",
            "Epoch: 98 train Loss: 0.0008 Acc: 1.0000\n",
            "Epoch: 98 eval Loss: 1.5258 Acc: 0.7812\n",
            "Epoch: 99 train Loss: 0.0011 Acc: 1.0000\n",
            "Epoch: 99 eval Loss: 1.5292 Acc: 0.7812\n",
            "Fold 4 accuracy: 0.8125 achieved in epoch 16\n",
            "Train:  [  0   2   4   5   6   7   8   9  10  11  13  14  15  16  17  19  20  21\n",
            "  22  23  24  25  26  27  28  29  31  32  33  34  35  36  37  38  39  41\n",
            "  42  43  44  45  46  47  48  49  52  53  54  55  56  57  58  60  62  63\n",
            "  64  65  66  68  69  70  72  73  74  75  76  77  78  79  80  81  82  83\n",
            "  85  86  87  88  89  90  91  92  95  96  98  99 100 102 103 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 119 120 121 123 125 126 127 128\n",
            " 129 130 132 133 134 135 136 139 140 141 142 143 145 147 148 150 151 152\n",
            " 153 154 155 156 157 158 159 160 161 162 164 166 167 168 169 170 171 172\n",
            " 173 174 175 177 178 179 180 181 182 183 184 186 187 188 190 191] Validation:  [  1   3  12  18  30  40  50  51  59  61  67  71  84  93  94  97 101 104\n",
            " 118 122 124 131 137 138 144 146 149 163 165 176 185 189]\n",
            "Epoch: 0 train Loss: 8.2749 Acc: 0.1500\n",
            "Epoch: 0 eval Loss: 1.2483 Acc: 0.4375\n",
            "Epoch: 1 train Loss: 1.1858 Acc: 0.2000\n",
            "Epoch: 1 eval Loss: 1.0492 Acc: 0.3438\n",
            "Epoch: 2 train Loss: 1.0594 Acc: 0.3688\n",
            "Epoch: 2 eval Loss: 1.0014 Acc: 0.6562\n",
            "Epoch: 3 train Loss: 0.9860 Acc: 0.5312\n",
            "Epoch: 3 eval Loss: 0.8461 Acc: 0.7188\n",
            "Epoch: 4 train Loss: 0.8526 Acc: 0.6313\n",
            "Epoch: 4 eval Loss: 0.7596 Acc: 0.6562\n",
            "Epoch: 5 train Loss: 0.6981 Acc: 0.6750\n",
            "Epoch: 5 eval Loss: 0.7492 Acc: 0.6562\n",
            "Epoch: 6 train Loss: 0.5972 Acc: 0.7250\n",
            "Epoch: 6 eval Loss: 0.6638 Acc: 0.7812\n",
            "Epoch: 7 train Loss: 0.4589 Acc: 0.8063\n",
            "Epoch: 7 eval Loss: 0.4214 Acc: 0.8438\n",
            "Epoch: 8 train Loss: 0.3352 Acc: 0.8688\n",
            "Epoch: 8 eval Loss: 0.3840 Acc: 0.8438\n",
            "Epoch: 9 train Loss: 0.2156 Acc: 0.8938\n",
            "Epoch: 9 eval Loss: 0.4976 Acc: 0.8438\n",
            "Epoch: 10 train Loss: 0.1389 Acc: 0.9438\n",
            "Epoch: 10 eval Loss: 0.4308 Acc: 0.8750\n",
            "Epoch: 11 train Loss: 0.0833 Acc: 0.9688\n",
            "Epoch: 11 eval Loss: 0.4555 Acc: 0.9062\n",
            "Epoch: 12 train Loss: 0.0507 Acc: 0.9813\n",
            "Epoch: 12 eval Loss: 0.4854 Acc: 0.8438\n",
            "Epoch: 13 train Loss: 0.1837 Acc: 0.9625\n",
            "Epoch: 13 eval Loss: 3.7804 Acc: 0.7188\n",
            "Epoch: 14 train Loss: 0.2209 Acc: 0.9500\n",
            "Epoch: 14 eval Loss: 2.6322 Acc: 0.7500\n",
            "Epoch: 15 train Loss: 0.4025 Acc: 0.8750\n",
            "Epoch: 15 eval Loss: 3.0558 Acc: 0.7500\n",
            "Epoch: 16 train Loss: 0.3972 Acc: 0.8688\n",
            "Epoch: 16 eval Loss: 0.8486 Acc: 0.7500\n",
            "Epoch: 17 train Loss: 0.9471 Acc: 0.7500\n",
            "Epoch: 17 eval Loss: 0.7903 Acc: 0.6875\n",
            "Epoch: 18 train Loss: 0.3076 Acc: 0.8625\n",
            "Epoch: 18 eval Loss: 1.1740 Acc: 0.6875\n",
            "Epoch: 19 train Loss: 0.4588 Acc: 0.8313\n",
            "Epoch: 19 eval Loss: 0.6341 Acc: 0.7500\n",
            "Epoch: 20 train Loss: 0.2869 Acc: 0.9062\n",
            "Epoch: 20 eval Loss: 0.6770 Acc: 0.7812\n",
            "Epoch: 21 train Loss: 0.2017 Acc: 0.9375\n",
            "Epoch: 21 eval Loss: 0.8518 Acc: 0.7500\n",
            "Epoch: 22 train Loss: 0.1401 Acc: 0.9500\n",
            "Epoch: 22 eval Loss: 0.8361 Acc: 0.8438\n",
            "Epoch: 23 train Loss: 0.1044 Acc: 0.9625\n",
            "Epoch: 23 eval Loss: 0.8538 Acc: 0.8438\n",
            "Epoch: 24 train Loss: 0.0827 Acc: 0.9625\n",
            "Epoch: 24 eval Loss: 0.8698 Acc: 0.8438\n",
            "Epoch: 25 train Loss: 0.0744 Acc: 0.9563\n",
            "Epoch: 25 eval Loss: 0.8282 Acc: 0.8438\n",
            "Epoch: 26 train Loss: 0.0618 Acc: 0.9750\n",
            "Epoch: 26 eval Loss: 0.7767 Acc: 0.8438\n",
            "Epoch: 27 train Loss: 0.0426 Acc: 0.9750\n",
            "Epoch: 27 eval Loss: 0.7426 Acc: 0.8438\n",
            "Epoch: 28 train Loss: 0.0443 Acc: 0.9688\n",
            "Epoch: 28 eval Loss: 0.7266 Acc: 0.8438\n",
            "Epoch: 29 train Loss: 0.0323 Acc: 0.9750\n",
            "Epoch: 29 eval Loss: 0.7335 Acc: 0.8125\n",
            "Epoch: 30 train Loss: 0.0246 Acc: 1.0000\n",
            "Epoch: 30 eval Loss: 0.7459 Acc: 0.8438\n",
            "Epoch: 31 train Loss: 0.0150 Acc: 1.0000\n",
            "Epoch: 31 eval Loss: 0.7619 Acc: 0.8438\n",
            "Epoch: 32 train Loss: 0.0095 Acc: 1.0000\n",
            "Epoch: 32 eval Loss: 0.7878 Acc: 0.8438\n",
            "Epoch: 33 train Loss: 0.0078 Acc: 1.0000\n",
            "Epoch: 33 eval Loss: 0.8199 Acc: 0.8438\n",
            "Epoch: 34 train Loss: 0.0064 Acc: 1.0000\n",
            "Epoch: 34 eval Loss: 0.8554 Acc: 0.8438\n",
            "Epoch: 35 train Loss: 0.0054 Acc: 1.0000\n",
            "Epoch: 35 eval Loss: 0.8803 Acc: 0.8438\n",
            "Epoch: 36 train Loss: 0.0029 Acc: 1.0000\n",
            "Epoch: 36 eval Loss: 0.9008 Acc: 0.8438\n",
            "Epoch: 37 train Loss: 0.0025 Acc: 1.0000\n",
            "Epoch: 37 eval Loss: 0.9178 Acc: 0.8438\n",
            "Epoch: 38 train Loss: 0.0036 Acc: 1.0000\n",
            "Epoch: 38 eval Loss: 0.9462 Acc: 0.8438\n",
            "Epoch: 39 train Loss: 0.0024 Acc: 1.0000\n",
            "Epoch: 39 eval Loss: 0.9765 Acc: 0.8438\n",
            "Epoch: 40 train Loss: 0.0021 Acc: 1.0000\n",
            "Epoch: 40 eval Loss: 0.9997 Acc: 0.8438\n",
            "Epoch: 41 train Loss: 0.0021 Acc: 1.0000\n",
            "Epoch: 41 eval Loss: 1.0168 Acc: 0.8438\n",
            "Epoch: 42 train Loss: 0.0016 Acc: 1.0000\n",
            "Epoch: 42 eval Loss: 1.0307 Acc: 0.8438\n",
            "Epoch: 43 train Loss: 0.0018 Acc: 1.0000\n",
            "Epoch: 43 eval Loss: 1.0438 Acc: 0.8438\n",
            "Epoch: 44 train Loss: 0.0016 Acc: 1.0000\n",
            "Epoch: 44 eval Loss: 1.0531 Acc: 0.8438\n",
            "Epoch: 45 train Loss: 0.0010 Acc: 1.0000\n",
            "Epoch: 45 eval Loss: 1.0623 Acc: 0.8438\n",
            "Epoch: 46 train Loss: 0.0012 Acc: 1.0000\n",
            "Epoch: 46 eval Loss: 1.0708 Acc: 0.8438\n",
            "Epoch: 47 train Loss: 0.0007 Acc: 1.0000\n",
            "Epoch: 47 eval Loss: 1.0785 Acc: 0.8438\n",
            "Epoch: 48 train Loss: 0.0009 Acc: 1.0000\n",
            "Epoch: 48 eval Loss: 1.0862 Acc: 0.8438\n",
            "Epoch: 49 train Loss: 0.0009 Acc: 1.0000\n",
            "Epoch: 49 eval Loss: 1.0933 Acc: 0.8438\n",
            "Epoch: 50 train Loss: 0.0008 Acc: 1.0000\n",
            "Epoch: 50 eval Loss: 1.0999 Acc: 0.8438\n",
            "Epoch: 51 train Loss: 0.0008 Acc: 1.0000\n",
            "Epoch: 51 eval Loss: 1.1060 Acc: 0.8438\n",
            "Epoch: 52 train Loss: 0.0008 Acc: 1.0000\n",
            "Epoch: 52 eval Loss: 1.1124 Acc: 0.8438\n",
            "Epoch: 53 train Loss: 0.0005 Acc: 1.0000\n",
            "Epoch: 53 eval Loss: 1.1186 Acc: 0.8438\n",
            "Epoch: 54 train Loss: 0.0005 Acc: 1.0000\n",
            "Epoch: 54 eval Loss: 1.1247 Acc: 0.8438\n",
            "Epoch: 55 train Loss: 0.0014 Acc: 1.0000\n",
            "Epoch: 55 eval Loss: 1.1589 Acc: 0.8438\n",
            "Epoch: 56 train Loss: 0.0006 Acc: 1.0000\n",
            "Epoch: 56 eval Loss: 1.1729 Acc: 0.8438\n",
            "Epoch: 57 train Loss: 0.0007 Acc: 1.0000\n",
            "Epoch: 57 eval Loss: 1.1710 Acc: 0.8438\n",
            "Epoch: 58 train Loss: 0.0007 Acc: 1.0000\n",
            "Epoch: 58 eval Loss: 1.1664 Acc: 0.8438\n",
            "Epoch: 59 train Loss: 0.0007 Acc: 1.0000\n",
            "Epoch: 59 eval Loss: 1.1625 Acc: 0.8438\n",
            "Epoch: 60 train Loss: 0.0006 Acc: 1.0000\n",
            "Epoch: 60 eval Loss: 1.1637 Acc: 0.8438\n",
            "Epoch: 61 train Loss: 0.0008 Acc: 1.0000\n",
            "Epoch: 61 eval Loss: 1.1681 Acc: 0.8438\n",
            "Epoch: 62 train Loss: 0.0005 Acc: 1.0000\n",
            "Epoch: 62 eval Loss: 1.1809 Acc: 0.8438\n",
            "Epoch: 63 train Loss: 0.0005 Acc: 1.0000\n",
            "Epoch: 63 eval Loss: 1.1983 Acc: 0.8438\n",
            "Epoch: 64 train Loss: 0.0007 Acc: 1.0000\n",
            "Epoch: 64 eval Loss: 1.2115 Acc: 0.8438\n",
            "Epoch: 65 train Loss: 0.0005 Acc: 1.0000\n",
            "Epoch: 65 eval Loss: 1.2222 Acc: 0.8438\n",
            "Epoch: 66 train Loss: 0.0007 Acc: 1.0000\n",
            "Epoch: 66 eval Loss: 1.2300 Acc: 0.8125\n",
            "Epoch: 67 train Loss: 0.0007 Acc: 1.0000\n",
            "Epoch: 67 eval Loss: 1.2410 Acc: 0.8125\n",
            "Epoch: 68 train Loss: 0.0006 Acc: 1.0000\n",
            "Epoch: 68 eval Loss: 1.2503 Acc: 0.8125\n",
            "Epoch: 69 train Loss: 0.0004 Acc: 1.0000\n",
            "Epoch: 69 eval Loss: 1.2575 Acc: 0.8125\n",
            "Epoch: 70 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 70 eval Loss: 1.2630 Acc: 0.8125\n",
            "Epoch: 71 train Loss: 0.0004 Acc: 1.0000\n",
            "Epoch: 71 eval Loss: 1.2675 Acc: 0.8125\n",
            "Epoch: 72 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 72 eval Loss: 1.2713 Acc: 0.8125\n",
            "Epoch: 73 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 73 eval Loss: 1.2746 Acc: 0.8125\n",
            "Epoch: 74 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 74 eval Loss: 1.2777 Acc: 0.8125\n",
            "Epoch: 75 train Loss: 0.0004 Acc: 1.0000\n",
            "Epoch: 75 eval Loss: 1.2807 Acc: 0.8125\n",
            "Epoch: 76 train Loss: 0.0005 Acc: 1.0000\n",
            "Epoch: 76 eval Loss: 1.2837 Acc: 0.8125\n",
            "Epoch: 77 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 77 eval Loss: 1.2863 Acc: 0.8125\n",
            "Epoch: 78 train Loss: 0.0004 Acc: 1.0000\n",
            "Epoch: 78 eval Loss: 1.2890 Acc: 0.8125\n",
            "Epoch: 79 train Loss: 0.0006 Acc: 1.0000\n",
            "Epoch: 79 eval Loss: 1.2910 Acc: 0.8125\n",
            "Epoch: 80 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 80 eval Loss: 1.2924 Acc: 0.8125\n",
            "Epoch: 81 train Loss: 0.0004 Acc: 1.0000\n",
            "Epoch: 81 eval Loss: 1.2944 Acc: 0.8125\n",
            "Epoch: 82 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 82 eval Loss: 1.2962 Acc: 0.8125\n",
            "Epoch: 83 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 83 eval Loss: 1.2983 Acc: 0.8125\n",
            "Epoch: 84 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 84 eval Loss: 1.3000 Acc: 0.8125\n",
            "Epoch: 85 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 85 eval Loss: 1.3014 Acc: 0.8125\n",
            "Epoch: 86 train Loss: 0.0004 Acc: 1.0000\n",
            "Epoch: 86 eval Loss: 1.3022 Acc: 0.8125\n",
            "Epoch: 87 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 87 eval Loss: 1.3030 Acc: 0.8125\n",
            "Epoch: 88 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 88 eval Loss: 1.3053 Acc: 0.8125\n",
            "Epoch: 89 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 89 eval Loss: 1.3084 Acc: 0.8125\n",
            "Epoch: 90 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 90 eval Loss: 1.3108 Acc: 0.8125\n",
            "Epoch: 91 train Loss: 0.0003 Acc: 1.0000\n",
            "Epoch: 91 eval Loss: 1.3127 Acc: 0.8125\n",
            "Epoch: 92 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 92 eval Loss: 1.3142 Acc: 0.8125\n",
            "Epoch: 93 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 93 eval Loss: 1.3154 Acc: 0.8125\n",
            "Epoch: 94 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 94 eval Loss: 1.3164 Acc: 0.8125\n",
            "Epoch: 95 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 95 eval Loss: 1.3175 Acc: 0.8125\n",
            "Epoch: 96 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 96 eval Loss: 1.3187 Acc: 0.8125\n",
            "Epoch: 97 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 97 eval Loss: 1.3197 Acc: 0.8125\n",
            "Epoch: 98 train Loss: 0.0001 Acc: 1.0000\n",
            "Epoch: 98 eval Loss: 1.3206 Acc: 0.8125\n",
            "Epoch: 99 train Loss: 0.0002 Acc: 1.0000\n",
            "Epoch: 99 eval Loss: 1.3218 Acc: 0.8125\n",
            "Fold 5 accuracy: 0.90625 achieved in epoch 11\n",
            "Finished Training, took 78m 27s\n",
            "Average accuracy: 0.8489583333333333\n",
            "Average epoch: 21.166666666666668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "avg. accuracies (step size 7, gamma 0.1)\n",
        "- 50 epochs, batch size 32, lr 0.001 : 0.4\n",
        "- 50 epochs, batch size 32, lr 0.0005: 0.4\n",
        "- 50 epochs, batch size 16, lr 0.001: 0.38\n",
        "- VGG16_bn, 50 epochs, batch size 32, lr: 0.001: 0.43\n",
        "- VGG16_bn, 50 epochs, batch size 32, lr: 0.004: 0.39\n",
        "\n",
        "avg. accuracies (step size 10, gamma 0.05)\n",
        "- VGG16_bn, 50 epochs, batch size 32, lr: 0.001: 0.56\n",
        "- VGG16_bn, 100 epochs, batch size 32, lr: 0.001, step size: 15, gamma: 0.05: 0.49\n",
        "- VGG16_bn, 50 epochs, batch size 32, lr: 0.001, no LR scheduler: 0.78\n",
        "- VGG16_bn, 50 epochs, batch size 40, lr: 0.001, no LR scheduler [note: overfitting after epoch 26]: 0.807\n",
        "- VGG16_bn, 50 epochs, batch size 40, lr: 0.001, step size: 25, gamma: 0.05: 0.67\n",
        "- VGG16_bn, 50 epochs, batch size 40, lr: 0.001, step size: 25, gamma: 0.90: 0.807\n",
        "- VGG16_bn, 50 epochs, batch size 40, lr: 0.001, step size: 25, gamma: 0.95: 0.807\n",
        "- **VGG16_bn, 100 epochs, batch size 40, lr: 0.001, step size: 25, gamma: 0.95: 0.848**\n",
        "- VGG16_bn, 50 epochs, batch size 40, lr: 0.001, step size: 25, gamma: 0.85: 0.76\n"
      ],
      "metadata": {
        "id": "p5GYTWjSD_6y"
      }
    }
  ]
}